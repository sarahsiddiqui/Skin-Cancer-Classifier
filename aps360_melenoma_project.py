# -*- coding: utf-8 -*-
"""APS360_Melenoma_Project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qzEimsR_CgnDk6HAAKqV0HkH0s4Rh-Km

apsthreesixtytwentyfive@gmail.com

aps36025
"""

from google.colab import drive
drive.mount('/content/gdrive')

import gc
gc.collect()

gc.collect()

!pip install torch torchvision torchaudio

import numpy as np
import time
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import torchvision
from torch.utils.data.sampler import SubsetRandomSampler
import torchvision.transforms as transforms
import matplotlib.pyplot as plt
import copy
import os
import pandas as pd
from PIL import Image
from torch.utils.data import random_split

"""### ALREADY DONE --- DOWNLOADED ALL DATA"""

! pip install -q kaggle
from google.colab import files
files.upload()

! mkdir /content/gdrive/MyDrive/kaggle
! cp kaggle.json /content/gdrive/MyDrive/kaggle/

! chmod 600 /content/gdrive/MyDrive/kaggle/kaggle.json

! kaggle datasets list

! kaggle datasets download -d kmader/skin-cancer-mnist-ham10000

! mkdir /content/gdrive/MyDrive/skinCancerData

! unzip skin-cancer-mnist-ham10000.zip -d /content/gdrive/MyDrive/skinCancerData

"""### DATA CLEANING -- DOWNLOADED TO DRIVE TOO"""

# data cleaning steps
# move all our code into a new function, ensure it runs
# use the current code to save the newly formatted data to a new files, one file
# for each catagory
  # As you save the code to the new file, double check for duplicates using a
  # list of the image names
# check the length of each file, find the smallest length, save that number of
# examples from each catagory to a final file


def clean_data():

    classes = ('akiec', 'bcc', 'bkl', 'df', 'mel', 'nv', 'vasc')

    dataset_dir = '/content/gdrive/MyDrive/skinCancerData/HAM10000_images_part_1/'
    metadata_csv = '/content/gdrive/MyDrive/skinCancerData/HAM10000_metadata.csv'

    # Maybe change this based on lab 3, theres 7 classes, not 2
    transform = transforms.Compose(
        [transforms.ToTensor(),
        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])

    metadata_df = pd.read_csv(metadata_csv)

    image_data = []

    image_names = []

    akiec_img = []
    bcc_img = []
    bkl_img = []
    df_img = []
    mel_img = []
    nv_img = []
    vasc_img = []


    i = 0
    for filename in os.listdir(dataset_dir):
        if filename.endswith('.jpg'):

            image_path = os.path.join(dataset_dir, filename)

            image = Image.open(image_path).convert('RGB')  # Ensure RGB format
            image = transform(image)

            image_id = os.path.splitext(filename)[0]

            # for testing
            #image_load = Image.open(os.path.join(dataset_dir, filename))
            #print("file path: ", os.path.join(dataset_dir, filename))
            #image_load = torchvision.datasets.ImageFolder(root = os.path.join(dataset_dir, filename), transform=transform)
            #image_id = os.path.splitext(filename)[0]  # Extract image_id from filename

            dx = metadata_df.loc[metadata_df['image_id'] == image_id, 'dx'].values[0]  # Get dx from metadata
            #image_data.append({'image_id': image_id, 'dx': dx})
            dx_label = classes.index(dx)

            if (image_id not in image_names): # This if statment checks to make sure there are no duplicates on the images already in the training data
                image_names.append(image_id)

                # these statments sort the data by their diagnosis
                if dx == 'akiec':
                    akiec_img.append({image_id, image, dx_label})
                elif dx == 'bcc':
                    bcc_img.append({image_id, image, dx_label})
                elif dx == 'bkl':
                    bkl_img.append({image_id, image, dx_label})
                elif dx == 'df':
                    df_img.append({image_id, image, dx_label})
                elif dx == 'mel':
                    mel_img.append({image_id, image, dx_label})
                elif dx == 'nv':
                    nv_img.append({image_id, image, dx_label})
                elif dx == 'vasc':
                    vasc_img.append({image_id, image, dx_label})


            #image_data.append({image_id, image, dx_label})
            #image_data.append({'image_id': image_id, 'dx': dx})
            #i += 1
            #break
    print("done")
    minimum = min(len(akiec_img), len(bcc_img), len(bkl_img), len(df_img), len(mel_img), len(nv_img), len(vasc_img))
    print("minimum: ", minimum)
    final_dataset = [].append(akiec_img[:minimum]).append(bcc_img[:minimum]).append(bkl_img[:minimum]).append(df_img[:minimum]).append(mel_img[:minimum]).append(nv_img[:minimum]).append(vasc_img[:minimum])
    print("final_dataset length: ", len(final_dataset))

    for data in image_data:
        print("data: ", data)

import os
from PIL import Image
import pandas as pd
import torchvision.transforms as transforms
import torch

def clean_data_1():

  classes = ('akiec', 'bcc', 'bkl', 'df', 'mel', 'nv', 'vasc')
  dataset_dir = '/content/gdrive/MyDrive/skinCancerData/HAM10000_images_part_1/'
  metadata_csv = '/content/gdrive/MyDrive/skinCancerData/HAM10000_metadata.csv'

  metadata_df = pd.read_csv(metadata_csv)

  transform = transforms.Compose([
      transforms.ToTensor(),
      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
  ])


  save_dir = '/content/gdrive/MyDrive/skinCancerData/saved_images_by_class/'
  os.makedirs(save_dir, exist_ok=True)


  saved_images = []
  for filename in os.listdir(dataset_dir):
      if filename.endswith('.jpg'):
          image_path = os.path.join(dataset_dir, filename)

          image = Image.open(image_path).convert('RGB')

          image_tensor = transform(image)

          image_id = os.path.splitext(filename)[0]

          dx = metadata_df.loc[metadata_df['image_id'] == image_id, 'dx'].values[0]
          dx_label = classes.index(dx)

          if(image_id not in saved_images):
            saved_images.append(image_id)
            data_to_save = {
                'image_tensor': image_tensor,
                'dx_label': dx_label
            }

            class_dir = os.path.join(save_dir, dx)
            os.makedirs(class_dir, exist_ok=True)

            save_path = os.path.join(class_dir, f'{image_id}.pt')

            torch.save(data_to_save, save_path)

            print(f"Saved: {save_path}")

  print("Processing complete.")

"""### V ACTUAL CLEAN DATA"""

def clean_data_2():
  classes = ('akiec', 'bcc', 'bkl', 'df', 'mel', 'nv', 'vasc')

  save_dir = '/content/gdrive/MyDrive/skinCancerData/saved_images_by_class/'

=  class_counts = {}

  for class_name in os.listdir(save_dir):
      class_dir = os.path.join(save_dir, class_name)

      if os.path.isdir(class_dir):
          file_count = len([filename for filename in os.listdir(class_dir) if filename.endswith('.pt')])

          class_counts[class_name] = file_count
          print(f"Class: {class_name}, Number of Files: {file_count}")

  min_files = min(class_counts.values())

  for class_name, count in class_counts.items():
      class_dir = os.path.join(save_dir, class_name)

      if count > min_files:
          files_to_delete = os.listdir(class_dir)

          files_to_delete.sort()

          for filename in files_to_delete[min_files:]:
              if filename.endswith('.pt'):
                  file_path = os.path.join(class_dir, filename)
                  os.remove(file_path)
                  print(f"Deleted: {file_path}")

  print("\nFiles adjusted to have equal counts.")

clean_data_2()

"""### HELPER FUNCTIONS"""

###############################################################################
# Data Loading

def get_relevant_indices(dataset, classes, target_classes):

    indices = []
    print(classes)
    print("The length of the dataset:", len(dataset))
    # dataset length = 50,000
    # dataset = {{[3 x 32 x 32], intger}, {[3 x 32 x 32], intger}, ... {[3 x 32 x 32], intger}}


    for i in range(0, len(dataset), 1000):
        # print the shape of dataset
        #print("Shape of dataset:", dataset[i][0].shape)
        print("dataset[i] length =", len(dataset[i]) )
        # Check if the label is in the target classes
        label_index = dataset[i][1] # ex: 3
        # plt.show(dataset[i][0])
        print("Label index:", label_index)
        label_class = classes[label_index] # ex: 'cat'
        if label_class in target_classes:
            indices.append(i)

    return indices

def get_data_loader(target_classes, batch_size):


    classes = ('akiec', 'bcc', 'bkl', 'df', 'mel', 'nv', 'vasc')




    # Melanocytic nevi (nv): Common moles, benign.
    # Melanoma (mel): A serious form of skin cancer.
    # Benign keratosis-like lesions (bkl): Includes seborrheic keratoses and solar lentigines, benign.
    # Basal cell carcinoma (bcc): A common type of skin cancer.
    # Actinic keratoses (akiec): Precancerous lesions that can develop into squamous cell carcinoma.
    # Vascular lesions (vasc): Includes cherry angiomas and angiokeratomas, benign.
    # Dermatofibroma (df): A benign skin lesion.

    ########################################################################

    transform = transforms.Compose(
        [transforms.ToTensor(),
         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])


    relevant_indices = get_relevant_indices(trainset, classes, target_classes)

    np.random.seed(1000)
    np.random.shuffle(relevant_indices)
    split = int(len(relevant_indices) * 0.8)


    relevant_train_indices, relevant_val_indices = relevant_indices[:split], relevant_indices[split:]
    train_sampler = SubsetRandomSampler(relevant_train_indices)
    train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,
                                               num_workers=1, sampler=train_sampler)
    val_sampler = SubsetRandomSampler(relevant_val_indices)
    val_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,
                                              num_workers=1, sampler=val_sampler)

    relevant_test_indices = get_relevant_indices(testset, classes, target_classes)
    test_sampler = SubsetRandomSampler(relevant_test_indices)
    test_loader = torch.utils.data.DataLoader(testset, batch_size=batch_size,
                                             num_workers=1, sampler=test_sampler)
    return train_loader, val_loader, test_loader, classes

# Downloads the CIFAR-10 dataset to "data"
# the first time you run this code.
train_loader, val_loader, test_loader, classes = get_data_loader(
    target_classes=['akiec', 'bcc', 'bkl', 'df', 'mel', 'nv', 'vasc'],
    batch_size=1) # One image per batch

    # basal cell carcinoma, melanoma or squamous cell carcinoma

"""### BASELINE MODELS"""

# Baseline model ANN

import torch
import torch.nn as nn
import torch.nn.functional as F
from torchvision import datasets, transforms
import matplotlib.pyplot as plt # for plotting
import torch.optim as optim
import torchvision


torch.manual_seed(1) # set the random seed

class Skin_cancer_Net(nn.Module):
    def __init__(self):
        super(Skin_cancer_Net, self).__init__()
        self.name = "Skin_cancer_Net"
        self.layer1 = nn.Linear(512*512*3, 50)
        self.layer2 = nn.Linear(50, 25)
        self.layer3 = nn.Linear(25, 7)

    def forward(self, img):
        flattened = img.view(-1, 512*512*3)
        activation1 = self.layer1(flattened)
        activation1 = F.relu(activation1)
        activation2 = self.layer2(activation1)
        activation2 = F.relu(activation2)
        activation3 = self.layer3(activation2)

        return activation2

import torch
import torchvision.transforms as transforms
from PIL import Image
import os
from PIL import Image

model_1 = Skin_cancer_Net()

transform = transforms.Compose(
    [transforms.Resize((512, 512)),
    transforms.ToTensor(),
     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])




# load the data
trainset = torchvision.datasets.ImageFolder(root='./drive/MyDrive/skinCancerData1', transform=transform)
print("dataseet loaded")
print(trainset[0])
print(trainset[1])
print(trainset[2])
#dataset = list(trainset[:2])



image_list = []

image_path = '/content/drive/MyDrive/skinCancerData1/HAM10000_images_part_1/ISIC_0024306.jpg'
image = Image.open(image_path)
# Apply transformations
image_tensor = transform(image)
# Add batch dimension if needed
image_tensor = image_tensor.unsqueeze(0)
img_cropped = image_tensor.squeeze(0).permute(1, 2, 0)

plt.imshow(img_cropped)

image_list.append(image_tensor)



image_path_1 = '/content/drive/MyDrive/skinCancerData1/HAM10000_images_part_1/ISIC_0024307.jpg'
image_1 = Image.open(image_path_1)
image_tensor_1 = transform(image_1)
image_tensor_1 = image_tensor_1.unsqueeze(0)
img_cropped_1 = image_tensor_1.squeeze(0).permute(1, 2, 0)

plt.imshow(img_cropped_1)

image_list.append(image_tensor_1)



image_path_2 = '/content/drive/MyDrive/skinCancerData1/HAM10000_images_part_1/ISIC_0024308.jpg'
image_2 = Image.open(image_path_2)
image_tensor_2 = transform(image_2)
image_tensor_2 = image_tensor_2.unsqueeze(0)
img_cropped_2 = image_tensor_2.squeeze(0).permute(1, 2, 0)

plt.imshow(img_cropped_2)

image_list.append(image_tensor_2)


for i in range(len(image_list)):
  print(i)
  plt.imshow(image_list[i])
  plt.show()

"""### ACTUAL BASELINE MODEL/ a lot of imports"""

import numpy as np
import time
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import torchvision
from torch.utils.data.sampler import SubsetRandomSampler
import torchvision.transforms as transforms
import matplotlib.pyplot as plt
import copy
import os
import pandas as pd
from PIL import Image
import os
from PIL import Image
import pandas as pd
import torchvision.transforms as transforms
import torch
from torchvision.datasets import ImageFolder
from torch.utils.data import DataLoader, Dataset, Subset, random_split, ConcatDataset
import torch
import torch.nn as nn
import torch.nn.functional as F
from torchvision import datasets, transforms
import matplotlib.pyplot as plt
import torch.optim as optim
import torchvision

from google.colab import drive
drive.mount('/content/drive')

# Baseline model ANN

torch.manual_seed(1)

class Skin_cancer_Net(nn.Module):
    def __init__(self):
        super(Skin_cancer_Net, self).__init__()
        self.name = "Skin_cancer_Net"
        self.layer1 = nn.Linear(512*512*3, 50)
        self.layer2 = nn.Linear(50, 25)
        self.layer3 = nn.Linear(25, 5)

    def forward(self, img):
        flattened = img.view(-1, 512*512*3)
        activation1 = self.layer1(flattened)
        activation1 = F.relu(activation1)
        activation2 = self.layer2(activation1)
        activation2 = F.relu(activation2)
        activation3 = self.layer3(activation2)



        return activation3

"""------------------------------

PRIMARY MODEL
"""

# Primary model CNN

torch.manual_seed(1)

class primary_skin_cancer_net1(nn.Module):
    def __init__(self):
        super(primary_skin_cancer_net1, self).__init__()
        self.name = "primary_skin_cancer_net"
        self.layer1 = nn.Conv2d(512*512*3, 50, 3)
        self.layer2 = nn.Conv2d(50, 25, 3)
        self.layer3 = nn.Conv2d(25, 7, 3)
        self.pool = nn.MaxPool2d(2,2)

    def forward(self, img):
        activation1 = self.pool(F.relu(self.layer1(img)))
        activation2 = self.pool(F.relu(self.layer2(activation1)))
        activation3 = self.layer3(activation2)



        return activation3

# Primary model CNN

torch.manual_seed(1)

class primary_skin_cancer_net2(nn.Module):
    def __init__(self):
        super(primary_skin_cancer_net, self).__init__()
        self.name = "primary_skin_cancer_net"
        self.layer1 = nn.Conv2d(3, 16, 3, 1)
        self.layer2 = nn.Conv2d(16, 32, 3, 1)
        self.layer3 = nn.Linear(32 * 128 * 128, 7)
        self.pool = nn.MaxPool2d(2,2)

    def forward(self, img):
        activation1 = self.pool(F.relu(self.layer1(img)))
        activation2 = self.pool(F.relu(self.layer2(activation1)))
        activation3 = self.layer3(activation2.view(activation2.size(0), -1))

        return activation3

import torch
import torch.nn as nn
import torch.nn.functional as F

torch.manual_seed(1)

class PrimarySkinCancerNet(nn.Module):
    def __init__(self):
        super(PrimarySkinCancerNet, self).__init__()
        self.name = "primary_skin_cancer_net"
        self.layer1 = nn.Conv2d(3, 16, 3, 1)
        self.layer2 = nn.Conv2d(16, 32, 3, 1)
        self.pool = nn.MaxPool2d(2, 2)
        self.layer3 = nn.Linear(32 * 126 * 126, 7)

    def forward(self, img):
        activation1 = self.pool(F.relu(self.layer1(img)))
        activation2 = self.pool(F.relu(self.layer2(activation1)))
        activation3 = self.layer3(activation2.view(activation2.size(0), -1))

        return activation3

"""# Primary Model Iteration 2"""

# PrimarySkinCancerNet_V2

import torch
import torch.nn as nn
import torch.nn.functional as F

torch.manual_seed(1)

class PrimarySkinCancerNet_V2(nn.Module):
    def __init__(self):
        super(PrimarySkinCancerNet_V2, self).__init__()
        self.name = "primary_skin_cancer_net"
        self.layer1 = nn.Conv2d(3, 16, 3, 1, 1)   # 256*256

        # with pooling 128*128

        self.layer2 = nn.Conv2d(16, 32, 2, 2)   #64*64
        self.pool = nn.MaxPool2d(2, 2)
        self.layer3 = nn.Linear(32 * 32 * 32, 7)

    def forward(self, img):
        activation1 = self.pool(F.relu(self.layer1(img)))
        activation2 = self.pool(F.relu(self.layer2(activation1)))
        activation3 = self.layer3(activation2.view(activation2.size(0), -1))

        return activation3

"""# Primary Model Iteration 3



"""

# PrimarySkinCancerNet_V3
# Same as V2, but has 5 outputs, not 7

import torch
import torch.nn as nn
import torch.nn.functional as F

torch.manual_seed(1)

class PrimarySkinCancerNet_V3(nn.Module):
    def __init__(self):
        super(PrimarySkinCancerNet_V3, self).__init__()
        self.name = "primary_skin_cancer_net"
        self.layer1 = nn.Conv2d(3, 16, 3, 1, 1)   # 256*256

        # with pooling 128*128

        self.layer2 = nn.Conv2d(16, 32, 2, 2)   #64*64
        self.pool = nn.MaxPool2d(2, 2)
        self.layer3 = nn.Linear(32 * 32 * 32, 5)

    def forward(self, img):
        activation1 = self.pool(F.relu(self.layer1(img)))
        activation2 = self.pool(F.relu(self.layer2(activation1)))
        activation3 = self.layer3(activation2.view(activation2.size(0), -1))

        return activation3

"""# Primary Model Iteration 4

"""

# PrimarySkinCancerNet_V4

import torch
import torch.nn as nn
import torch.nn.functional as F

torch.manual_seed(1)

class PrimarySkinCancerNet_V4(nn.Module):
    def __init__(self):
        super(PrimarySkinCancerNet_V4, self).__init__()
        self.name = "primary_skin_cancer_net"
        self.layer1 = nn.Conv2d(3, 8, 3, 1, 1)   # 512*512
        # with pooling 256*256
        self.layer2 = nn.Conv2d(8, 24, 1, 1)   #128*128
        self.layer3 = nn.Conv2d(24, 32, 1, 1)   #64*64
        self.layer4 = nn.Conv2d(32, 64, 1, 1)   #32*32
        self.pool = nn.MaxPool2d(2, 2)
        self.layer5 = nn.Linear(64 * 16 * 16, 100)
        self.layer6 = nn.Linear(100, 50)
        self.layer7 = nn.Linear(50, 5)
        self.pool = nn.MaxPool2d(2, 2)

    def forward(self, img):
        activation1 = self.pool(F.relu(self.layer1(img)))
        activation2 = self.pool(F.relu(self.layer2(activation1)))
        activation3 = self.pool(F.relu(self.layer3(activation2)))
        activation4 = self.pool(F.relu(self.layer4(activation3)))
        activation5 = self.layer5(activation4.view(activation4.size(0), -1))
        activation6 = self.layer6(activation5)
        activation7 = self.layer7(activation6)
        return activation7

"""------------------------------------------

# Primary Model Iteration 5
"""

import torch
import torch.nn as nn
import torch.nn.functional as F

torch.manual_seed(1)

class PrimarySkinCancerNet_V5(nn.Module):
    def __init__(self):
        super(PrimarySkinCancerNet_V5, self).__init__()
        self.name = "primary_skin_cancer_net"

        self.layer1 = nn.Conv2d(3, 32, 3, 1, 1)
        self.bn1 = nn.BatchNorm2d(32)
        self.layer2 = nn.Conv2d(32, 64, 3, 1, 1)
        self.bn2 = nn.BatchNorm2d(64)
        self.layer3 = nn.Conv2d(64, 128, 3, 1, 1)
        self.bn3 = nn.BatchNorm2d(128)
        self.layer4 = nn.Conv2d(128, 256, 3, 1, 1)
        self.bn4 = nn.BatchNorm2d(256)
        self.layer5 = nn.Conv2d(256, 512, 3, 1, 1)
        self.bn5 = nn.BatchNorm2d(512)
        self.layer6 = nn.Conv2d(512, 1024, 3, 1, 1)
        self.bn6 = nn.BatchNorm2d(1024)
        self.pool = nn.MaxPool2d(2, 2)

        self.global_pool = nn.AdaptiveAvgPool2d(1)

        self.fc1 = nn.Linear(1024, 256)
        self.dropout1 = nn.Dropout(0.4)
        self.fc2 = nn.Linear(256, 100)
        self.dropout2 = nn.Dropout(0.4)
        self.fc3 = nn.Linear(100, 5)

    def forward(self, img):
        x = self.pool(F.relu(self.bn1(self.layer1(img))))
        x = self.pool(F.relu(self.bn2(self.layer2(x))))
        x = self.pool(F.relu(self.bn3(self.layer3(x))))
        x = self.pool(F.relu(self.bn4(self.layer4(x))))
        x = self.pool(F.relu(self.bn5(self.layer5(x))))
        x = self.pool(F.relu(self.bn6(self.layer6(x))))

        x = self.global_pool(x)
        x = x.view(x.size(0), -1)

        x = F.relu(self.fc1(x))
        x = self.dropout1(x)
        x = F.relu(self.fc2(x))
        x = self.dropout2(x)
        x = self.fc3(x)

        return x

"""# Primary Model Iteration 6



"""

import torch
import torch.nn as nn
import torch.nn.functional as F

torch.manual_seed(1)

class PrimarySkinCancerNet_V6(nn.Module):
    def __init__(self, dropout_rate=0.5):
        super(PrimarySkinCancerNet_V6, self).__init__()
        self.name = "primary_skin_cancer_net"

        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)
        self.bn1 = nn.BatchNorm2d(16)
        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)
        self.bn2 = nn.BatchNorm2d(32)
        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)
        self.bn3 = nn.BatchNorm2d(64)
        self.conv4 = nn.Conv2d(64, 128, kernel_size=3, padding=1)
        self.bn4 = nn.BatchNorm2d(128)
        self.pool = nn.AdaptiveAvgPool2d((8, 8))
        self.dropout = nn.Dropout(dropout_rate)

        self.fc1 = nn.Linear(128 * 8 * 8, 256)
        self.fc2 = nn.Linear(256, 128)
        self.fc3 = nn.Linear(128, 5)

    def forward(self, x):
        x = self.pool(F.leaky_relu(self.bn1(self.conv1(x))))
        x = self.pool(F.leaky_relu(self.bn2(self.conv2(x))))
        x = self.pool(F.leaky_relu(self.bn3(self.conv3(x))))
        x = self.pool(F.leaky_relu(self.bn4(self.conv4(x))))

        x = x.view(x.size(0), -1)

        x = F.leaky_relu(self.fc1(x))
        x = self.dropout(x)
        x = F.leaky_relu(self.fc2(x))
        x = self.dropout(x)
        x = self.fc3(x)

        return x

"""#Primary Model Iteration 7"""

import torch
import torch.nn as nn
import torch.nn.functional as F

# Set the random seed for reproducibility
torch.manual_seed(1)

class PrimarySkinCancerNet_V7(nn.Module):
    def __init__(self, dropout_rate=0.5):
        super(PrimarySkinCancerNet_V7, self).__init__()
        self.name = "primary_skin_cancer_net"

        # convolutional layers with batch normalization
        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)
        self.bn1 = nn.BatchNorm2d(16)
        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)
        self.bn2 = nn.BatchNorm2d(32)
        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)
        self.bn3 = nn.BatchNorm2d(64)
        self.conv4 = nn.Conv2d(64, 128, kernel_size=3, padding=1)
        self.bn4 = nn.BatchNorm2d(128)

        # bottleneck layer
        self.bottleneck = nn.Conv2d(128, 64, kernel_size=1)
        self.bn_bottleneck = nn.BatchNorm2d(64)

        # adaptive pooling and dropout layers
        self.pool = nn.AdaptiveAvgPool2d((8, 8))
        self.dropout = nn.Dropout(dropout_rate)

        # fully connected layers
        self.fc1 = nn.Linear(64 * 8 * 8, 256)
        self.fc2 = nn.Linear(256, 128)
        self.fc3 = nn.Linear(128, 5)

    def forward(self, x):
        x = self.pool(F.leaky_relu(self.bn1(self.conv1(x))))
        x = self.pool(F.leaky_relu(self.bn2(self.conv2(x))))
        x = self.pool(F.leaky_relu(self.bn3(self.conv3(x))))
        x = self.pool(F.leaky_relu(self.bn4(self.conv4(x))))

        x = F.leaky_relu(self.bn_bottleneck(self.bottleneck(x)))

        x = x.view(x.size(0), -1)  # flatten the tensor

        x = F.leaky_relu(self.fc1(x))
        x = self.dropout(x)
        x = F.leaky_relu(self.fc2(x))
        x = self.dropout(x)
        x = self.fc3(x)

        return x

drive.flush_and_unmount()
drive.mount('/content/gdrive')

"""### DATALOADER BELOW"""

import os
import pandas as pd
from PIL import Image
from torchvision.transforms import transforms
from torch.utils.data import Dataset, DataLoader

def ANN_dataloader(data_paths, metadata_file, batch_size=32, shuffle=True):
    metadata = pd.read_csv(metadata_file)

    transform = transforms.Compose([
        transforms.Resize((256, 256)),  # Resize images to 224x224
        transforms.ToTensor(),          # Convert images to PyTorch tensors
    ])

    print("done with transforms")



    classes = sorted(metadata['dx'].unique())
    class_to_idx = {cls: i for i, cls in enumerate(classes)}

    dataset_1 = []
    dataset_2 = []
    dataset_3 = []

    i = 0
    for data_path in data_paths:
        for filename in os.listdir(data_path):
            if filename.endswith('.jpg') and i < 3000:
                img_name = os.path.splitext(filename)[0]
                img_path = os.path.join(data_path, filename)
                image = Image.open(img_path).convert('RGB')
                image = transform(image)
                dx_label = metadata.loc[metadata['image_id'] == img_name, 'dx'].values[0]
                label = class_to_idx[dx_label]
                if i < 1000:
                    dataset_1.append((image, label))
                elif i < 2000:
                    dataset_2.append((image, label))
                elif i < 3000:
                    dataset_3.append((image, label))
                print(img_name)
                i += 1


    data_loader_1 = DataLoader(dataset_1, batch_size=batch_size, shuffle=shuffle)
    data_loader_2 = DataLoader(dataset_2, batch_size=batch_size, shuffle=shuffle)
    data_loader_3 = DataLoader(dataset_3, batch_size=batch_size, shuffle=shuffle)


    return data_loader_1, data_loader_2, data_loader_3, classes, class_to_idx

data_paths = [
    '/content/gdrive/MyDrive/skinCancerData/HAM10000_images_part_1',
    '/content/gdrive/MyDrive/skinCancerData/HAM10000_images_part_2'
]
metadata_file = '/content/gdrive/MyDrive/skinCancerData/HAM10000_metadata.csv'

data_loader_1, data_loader_2, data_loader_3, classes, class_to_idx = ANN_dataloader(data_paths, metadata_file, batch_size=32, shuffle=True)

print(f"Number of classes: {len(classes)}")
print(f"Classes: {classes}")
print(f"Class to index mapping: {class_to_idx}")
print(f"Number of batches: {len(data_loader_1)}")

"""# Sorting data into files"""

# I'm saving this just to reference it late, you do not need to run it again!

# import pandas as pd
# import os
# import shutil

# # Path to the metadata CSV file
# metadata_path = '/content/gdrive/MyDrive/skinCancerData/HAM10000_metadata.csv'



# image_part1_path = '/content/gdrive/MyDrive/skinCancerData/HAM10000_images_part_1'
# image_part2_path = '/content/gdrive/MyDrive/skinCancerData/HAM10000_images_part_2'

# # Destination root directory for sorted images
# destination_root = '/content/gdrive/MyDrive/skinCancerData/sorted_images'

# # Function to create directories if they don't exist
# def create_directories(path):
#     if not os.path.exists(path):
#         os.makedirs(path)

# # Load metadata CSV into pandas DataFrame
# metadata_df = pd.read_csv(metadata_path)

# # Create the destination root directory if it doesn't exist
# create_directories(destination_root)

# # Iterate over each row in the DataFrame
# for index, row in metadata_df.iterrows():
#     image_id = row['image_id'] + '.jpg'  # Assuming image filenames end with '.jpg'
#     lesion_id = row['dx']

#     # Determine which part (folder) the image is in
#     if os.path.exists(os.path.join(image_part1_path, image_id)):
#         source_path = image_part1_path
#     elif os.path.exists(os.path.join(image_part2_path, image_id)):
#         source_path = image_part2_path
#     else:
#         print(f"Image '{image_id}' not found in either part 1 or part 2 folder.")
#         continue

#     # Destination directory for this label
#     destination_folder = os.path.join(destination_root, lesion_id)
#     create_directories(destination_folder)

#     # Move the image to the appropriate folder
#     shutil.move(os.path.join(source_path, image_id), os.path.join(destination_folder, image_id))

# print("Sorting complete.")

"""### Data Loader that balances classes"""

# Data loader, makes classes even

# Melanocytic nevi (nv): Common moles, benign.
# Melanoma (mel): A serious form of skin cancer.
# Benign keratosis-like lesions (bkl): Includes seborrheic keratoses and solar lentigines, benign.
# Basal cell carcinoma (bcc): A common type of skin cancer.
# Actinic keratoses (akiec): Precancerous lesions that can develop into squamous cell carcinoma.
# Vascular lesions (vasc): Includes cherry angiomas and angiokeratomas, benign.
# Dermatofibroma (df): A benign skin lesion.

import os
import pandas as pd
from PIL import Image
from torchvision.transforms import transforms
from torch.utils.data import Dataset, DataLoader

transform = transforms.Compose(
    [transforms.Resize((256, 256)),
    transforms.ToTensor(),
     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])



def ANN_dataloader(data_paths, metadata_file, batch_size=32, shuffle=True, transform = transform):
    metadata = pd.read_csv(metadata_file)
    classes = sorted(metadata['dx'].unique())
    class_to_idx = {cls: i for i, cls in enumerate(classes)}


    nv_dataset = []
    mel_dataset = []
    bkl_dataset = []
    bcc_dataset = []
    akiec_dataset = []
    vasc_dataset = []
    df_dataset = []



    for data_path in data_paths:
        print(len(os.listdir(data_path)))

        for filename in os.listdir(data_path):


            if filename.endswith('.jpg'):
                img_name = os.path.splitext(filename)[0]
                img_path = os.path.join(data_path, filename)
                image = Image.open(img_path).convert('RGB')
                image = transform(image)
                dx_label = metadata.loc[metadata['image_id'] == img_name, 'dx'].values[0]
                label = class_to_idx[dx_label]
                if dx_label == 'nv' and len(nv_dataset) < 115:
                    nv_dataset.append((image, label))
                    print(img_name)
                elif dx_label == 'mel' and len(mel_dataset) < 115:
                    mel_dataset.append((image, label))
                    print(img_name)
                elif dx_label == 'bkl' and len(bkl_dataset) < 115:
                    bkl_dataset.append((image, label))
                    print(img_name)
                elif dx_label == 'bcc' and len(bcc_dataset) < 115:
                    bcc_dataset.append((image, label))
                    print(img_name)
                elif dx_label == 'akiec' and len(akiec_dataset) < 115:
                    akiec_dataset.append((image, label))
                    print(img_name)
                elif dx_label == 'vasc' and len(vasc_dataset) < 115:
                    vasc_dataset.append((image, label))
                    print(img_name)
                elif dx_label == 'df' and len(df_dataset) < 115:
                    df_dataset.append((image, label))
                    print(img_name)

    nv_dataloader = DataLoader(nv_dataset, batch_size=23, shuffle=shuffle)
    mel_dataloader = DataLoader(mel_dataset, batch_size=23, shuffle=shuffle)
    bkl_dataloader = DataLoader(bkl_dataset, batch_size=23, shuffle=shuffle)
    bcc_dataloader = DataLoader(bcc_dataset, batch_size=23, shuffle=shuffle)
    akiec_dataloader = DataLoader(akiec_dataset, batch_size=23, shuffle=shuffle)
    vasc_dataloader = DataLoader(vasc_dataset, batch_size=23, shuffle=shuffle)
    df_dataloader = DataLoader(df_dataset, batch_size=23, shuffle=shuffle)



    return nv_dataloader, mel_dataloader, bkl_dataloader, bcc_dataloader, akiec_dataloader, vasc_dataloader, df_dataloader, classes, class_to_idx

data_paths = [
    '/content/gdrive/MyDrive/skinCancerData/HAM10000_images_part_1',
    '/content/gdrive/MyDrive/skinCancerData/HAM10000_images_part_2'
]
metadata_file = '/content/gdrive/MyDrive/skinCancerData/HAM10000_metadata.csv'



nv_dataloader, mel_dataloader, bkl_dataloader, bcc_dataloader, akiec_dataloader, vasc_dataloader, df_dataloader, classes, class_to_idx = ANN_dataloader(data_paths, metadata_file, batch_size=32, shuffle=True, transform = transform)

print(f"Number of classes: {len(classes)}")
print(f"Classes: {classes}")
print(f"Class to index mapping: {class_to_idx}")
print(f"Number of batches: {len(nv_dataloader)}")

for i, (images, labels) in enumerate(nv_dataloader):
  #print(images.shape)
  #print(labels)
  #break
  pass

print(i)

print(labels[0])
#convert labels[0] into an int
label = int(labels[0])
# convert labels into a tuple of tensors

# doesn't account for batches

model_1 = Skin_cancer_Net()


dataset_size = len(data_loader_1.dataset)
train_size = int(0.1 * dataset_size)
val_size = int(0.1*dataset_size)
test_size = int(0.8*dataset_size)

train_dataset_1, val_dataset_1, test_dataset_1 = random_split(data_loader_1.dataset, [train_size, val_size, test_size])
train_dataset_2, val_dataset_2, test_dataset_2 = random_split(data_loader_2.dataset, [train_size, val_size, test_size])
train_dataset_3, val_dataset_3, test_dataset_3 = random_split(data_loader_3.dataset, [train_size, val_size, test_size])


from torch.utils.data import ConcatDataset


train_datasets = [train_dataset_1, train_dataset_2, train_dataset_3]
train_dataset = ConcatDataset(train_datasets)
train_dataset = DataLoader(train_dataset, batch_size=32, shuffle=True)
for batch_idx, (inputs, targets) in enumerate(train_dataset):
  print("batch idx:", batch_idx)
  print("inputs:", inputs)
  print("targest:", targets)
  break

val_datasets = [val_dataset_1, val_dataset_2, val_dataset_3]
val_dataset = ConcatDataset(val_datasets)

test_datasets = [test_dataset_1, test_dataset_2, test_dataset_3]
test_dataset = ConcatDataset(test_datasets)


transform = transforms.Compose(
    [transforms.Resize((512, 512)),
    transforms.ToTensor(),
     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])


img_to_tensor = transforms.ToTensor()


criterion = nn.CrossEntropyLoss()
# was originally:
optimizer = optim.SGD(model_1.parameters(), lr=0.01, momentum=0.9)
#optimizer = optim.Adam(model_1.parameters(), lr=0.01)

#print("Before epoch")
#for epoch in range(1):    # line added to test how the number of itterations affects accuracy
#  print("epoch: ", epoch)
i = 0
epochs = 10
train_error = []
train_accuracy = []
validation_error = []
validation_accuracy = []
for i in range(epochs):
  for (image, label) in train_dataset:
      # print(batch[0][i])
      # print(batch[0][i].size)
      # print(labels)
      # for i in range(len(batch)):
        #image = batch[i]
        #print(image.size())
        #print(labels)
        label_one_hot = [[0, 0, 0, 0, 0, 0, 0]]
        label_one_hot[0][label] = 1
        label_tensor = torch.tensor(label_one_hot, dtype=torch.float)
        #print(label_tensor)
        #print(label_tensor.size())
        #label = labels[i]
        out = model_1(image) # step 1-2
        # update the parameters based on the loss
        loss = criterion(out, label_tensor)      # step 3
        loss.backward()                    # step 4 (compute the updates for each parameter)
        optimizer.step()                   # step 4 (make the updates for each parameter)
        optimizer.zero_grad()


              # computing the error and accuracy on the training set
  loss = 0
  accuracy = 0
  for (image, label) in train_dataset:
      prob = model_1(image)

      max_prob_index = torch.argmax(prob)

      if max_prob_index.item() == label:
          accuracy += 1

      true_label = [0, 0, 0, 0, 0, 0, 0]
      true_label[label] = 1
      true_label = torch.tensor(true_label)

      loss = criterion(prob, true_label)
      loss += loss.item()




  print("Training Loss:", loss/len(train_dataset))
  print("Training Accuracy:", 1 - error/len(train_dataset))
  train_error.append(error/len(train_dataset))
  train_accuracy.append(1 - error/len(train_dataset))


  error = 0
  for (image, label) in val_dataset:
      prob = model_1(image)
      max_prob_index = torch.argmax(prob)
      if max_prob_index.item() != label:
          error += 1
  print("Validation Error Rate:", error/len(val_dataset))
  print("Validation Accuracy:", 1 - error/len(val_dataset))
  validation_error.append(error/len(val_dataset))
  validation_accuracy.append(1 - error/len(val_dataset))
  print(i)
  i += 1

# uses batches

model_1 = Skin_cancer_Net()


dataset_size = len(data_loader_1.dataset)
train_size = int(0.1 * dataset_size)
val_size = int(0.1*dataset_size)
test_size = int(0.8*dataset_size)

train_dataset_1, val_dataset_1, test_dataset_1 = random_split(data_loader_1.dataset, [train_size, val_size, test_size])
train_dataset_2, val_dataset_2, test_dataset_2 = random_split(data_loader_2.dataset, [train_size, val_size, test_size])
train_dataset_3, val_dataset_3, test_dataset_3 = random_split(data_loader_3.dataset, [train_size, val_size, test_size])


from torch.utils.data import ConcatDataset

train_datasets = [train_dataset_1, train_dataset_2, train_dataset_3]
train_dataset = ConcatDataset(train_datasets)
train_dataset = DataLoader(train_dataset, batch_size=32, shuffle=True)
for batch_idx, (inputs, targets) in enumerate(train_dataset):
  print("batch idx:", batch_idx)
  print("inputs:", inputs)
  print("targest:", targets)
  break

val_datasets = [val_dataset_1, val_dataset_2, val_dataset_3]
val_dataset = ConcatDataset(val_datasets)
val_dataset = DataLoader(val_dataset, batch_size=30, shuffle=True)


test_datasets = [test_dataset_1, test_dataset_2, test_dataset_3]
test_dataset = ConcatDataset(test_datasets)
test_dataset = DataLoader(test_dataset, batch_size=30, shuffle=True)

print("train size, ", train_dataset[0][0].size)

transform = transforms.Compose(
    [transforms.Resize((512, 512)),
    transforms.ToTensor(),
     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])


img_to_tensor = transforms.ToTensor()


criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(model_1.parameters(), lr=0.01, momentum=0.9)


i = 0
epochs = 10
train_loss_list = []
train_accuracy_list = []
validation_loss = []
validation_accuracy = []
model_1.train()
for i in range(epochs):
  for batch_idx, (images, labels) in enumerate(train_dataset):

    out = model_1(images)
    loss = criterion(out, labels)
    loss.backward()
    optimizer.step()
    optimizer.zero_grad()


  train_loss = 0
  train_accuracy = 0
  n_imgs = 0
  for batch_idx, (images, label) in enumerate(train_dataset):
      prob = model_1(images)

      max_prob_indices = torch.argmax(prob, dim = 1)

      for i in range(len(max_prob_indices)):
        if max_prob_indices[i].item() == label[i]:
          train_accuracy += 1
        n_imgs += 1

      loss_batch = criterion(prob, label)
      train_loss += loss_batch.item()

  print("Training Loss:", train_loss/n_imgs)
  print("Training Accuracy:", train_accuracy/n_imgs)
  train_loss_list.append(train_loss/n_imgs)
  train_accuracy_list.append(train_accuracy/n_imgs)

  model_1.eval()
  val_loss = 0
  val_accuracy = 0
  n_imgs = 0
  for batch_idx, (images, label) in enumerate(val_dataset):
      prob = model_1(images)

      max_prob_indices = torch.argmax(prob, dim = 1)

      for i in range(len(max_prob_indices)):
        if max_prob_indices[i].item() == label[i]:
          val_accuracy += 1
        n_imgs += 1

      loss_batch = criterion(prob, label)
      val_loss += loss_batch.item()

  print("Validation Loss:", val_loss/n_imgs)
  print("Validation Accuracy:", val_accuracy/n_imgs)
  validation_loss.append(val_loss/n_imgs)
  validation_accuracy.append(val_accuracy/n_imgs)

test_loss = 0
test_accuracy = 0
n_imgs = 0
for batch_idx, (images, label) in enumerate(test_dataset):
    prob = model_1(images)

    max_prob_indices = torch.argmax(prob, dim = 1)

    for i in range(len(max_prob_indices)):
      if max_prob_indices[i].item() == label[i]:
        test_accuracy += 1
      n_imgs += 1
    loss_batch = criterion(prob, label)
    test_loss += loss_batch.item()

print("Test Loss:", test_loss/n_imgs)
print("Test Accuracy:", test_accuracy/n_imgs)



"""--------------------------------------------

### PRIMARY MODEL WITH BATCHES
"""

# Primary model with batches


model_2 = PrimarySkinCancerNet()




dataset_size = len(data_loader_1.dataset)
train_size = int(0.1 * dataset_size)
val_size = int(0.1*dataset_size)
test_size = int(0.8*dataset_size)

train_dataset_1, val_dataset_1, test_dataset_1 = random_split(data_loader_1.dataset, [train_size, val_size, test_size])
train_dataset_2, val_dataset_2, test_dataset_2 = random_split(data_loader_2.dataset, [train_size, val_size, test_size])
train_dataset_3, val_dataset_3, test_dataset_3 = random_split(data_loader_3.dataset, [train_size, val_size, test_size])


from torch.utils.data import ConcatDataset




train_datasets = [train_dataset_1, train_dataset_2, train_dataset_3]
train_dataset = ConcatDataset(train_datasets)
train_dataset = DataLoader(train_dataset, batch_size=32, shuffle=True)
# for batch_idx, (inputs, targets) in enumerate(train_dataset):
#   print("batch idx:", batch_idx)
#   print("inputs:", inputs)
#   print("targest:", targets)
#   break
del train_dataset_1, train_dataset_2, train_dataset_3

val_datasets = [val_dataset_1, val_dataset_2, val_dataset_3]
val_dataset = ConcatDataset(val_datasets)
val_dataset = DataLoader(val_dataset, batch_size=30, shuffle=True)

del val_dataset_1, val_dataset_2, val_dataset_3

test_datasets = [test_dataset_1, test_dataset_2, test_dataset_3]
test_dataset = ConcatDataset(test_datasets)
test_dataset = DataLoader(test_dataset, batch_size=30, shuffle=True)

del test_dataset_1, test_dataset_2, test_dataset_3



transform = transforms.Compose(
    [transforms.Resize((512, 512)),
    transforms.ToTensor(),
     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])


img_to_tensor = transforms.ToTensor()


criterion = nn.CrossEntropyLoss()
# was originally:
optimizer = optim.SGD(model_2.parameters(), lr=0.01, momentum=0.9)
#optimizer = optim.Adam(model_2.parameters(), lr=0.01)

#print("Before epoch")
#for epoch in range(1):    # line added to test how the number of itterations affects accuracy
#  print("epoch: ", epoch)
i = 0
epochs = 10
train_loss_list = []
train_accuracy_list = []
validation_loss = []
validation_accuracy = []
for i in range(epochs):
  model_2.train()
  for (image, label) in train_dataset:
  # for batch_idx, (images, labels) in enumerate(train_dataset):
  #   print("batch idx:", batch_idx)
  #   print("shape:", images.size())
  #   print("number of images: ", len(images))
  #   print("targest:", labels)

    out = model_2(image)
    # print("images:", len(image))
    # print("out: ", len(out))
    # print("labels: ", len(label))
    loss = criterion(out, label)
    loss.backward()
    optimizer.step()
    #optimizer.zero_grad()


  train_loss = 0
  train_accuracy = 0
  n_imgs = 0

  for batch_idx, (images, label) in enumerate(train_dataset):
      prob = model_2(images)
      max_prob_indices = torch.argmax(prob, dim = 1)

      for i in range(len(max_prob_indices)):
        if max_prob_indices[i].item() == label[i]:
          train_accuracy += 1
        n_imgs += 1

      #labels_one_hot = torch.nn.functional.one_hot(labels, num_classes=7).float()

      loss_batch = criterion(prob, label)
      train_loss += loss_batch.item()

  print("Training Loss:", train_loss/n_imgs)
  print("Training Accuracy:", train_accuracy/n_imgs)
  train_loss_list.append(train_loss/n_imgs)
  train_accuracy_list.append(train_accuracy/n_imgs)


  val_loss = 0
  val_accuracy = 0
  n_imgs = 0
  model_2.eval()
  for batch_idx, (images, label) in enumerate(val_dataset):

      prob = model_2(images)

      max_prob_indices = torch.argmax(prob, dim = 1)

      for i in range(len(max_prob_indices)):
        if max_prob_indices[i].item() == label[i]:
          val_accuracy += 1
        n_imgs += 1

      loss_batch = criterion(prob, label)
      val_loss += loss_batch.item()

  print("Validation Loss:", val_loss/n_imgs)
  print("Validation Accuracy:", val_accuracy/n_imgs)
  validation_loss.append(val_loss/n_imgs)
  validation_accuracy.append(val_accuracy/n_imgs)




# test loss and accuracy


test_loss = 0
test_accuracy = 0
n_imgs = 0
for batch_idx, (images, label) in enumerate(test_dataset):
    prob = model_2(images)

    max_prob_indices = torch.argmax(prob, dim = 1)

    for i in range(len(max_prob_indices)):
      if max_prob_indices[i].item() == label[i]:
        test_accuracy += 1
      n_imgs += 1
    loss_batch = criterion(prob, label)
    test_loss += loss_batch.item()

print("Test Loss:", test_loss/n_imgs)
print("Test Accuracy:", test_accuracy/n_imgs)

dataset_size = len(data_loader_1.dataset)
train_size = int(0.1 * dataset_size)
val_size = int(0.1*dataset_size)
test_size = int(0.8*dataset_size)

train_dataset_1, val_dataset_1, test_dataset_1 = random_split(data_loader_1.dataset, [train_size, val_size, test_size])
train_dataset_2, val_dataset_2, test_dataset_2 = random_split(data_loader_2.dataset, [train_size, val_size, test_size])
train_dataset_3, val_dataset_3, test_dataset_3 = random_split(data_loader_3.dataset, [train_size, val_size, test_size])


from torch.utils.data import ConcatDataset




train_datasets = [train_dataset_1, train_dataset_2, train_dataset_3]
train_dataset = ConcatDataset(train_datasets)
train_dataset = DataLoader(train_dataset, batch_size=32, shuffle=True)
# for batch_idx, (inputs, targets) in enumerate(train_dataset):
#   print("batch idx:", batch_idx)
#   print("inputs:", inputs)
#   print("targest:", targets)
#   break
del train_dataset_1, train_dataset_2, train_dataset_3


val_datasets = [val_dataset_1, val_dataset_2, val_dataset_3]
val_dataset = ConcatDataset(val_datasets)
val_dataset = DataLoader(val_dataset, batch_size=30, shuffle=True)

del val_dataset_1, val_dataset_2, val_dataset_3


test_datasets = [test_dataset_1, test_dataset_2, test_dataset_3]
test_dataset = ConcatDataset(test_datasets)
test_dataset = DataLoader(test_dataset, batch_size=30, shuffle=True)

del test_dataset_1, test_dataset_2, test_dataset_3



transform = transforms.Compose(
    [transforms.Resize((512, 512)),
    transforms.ToTensor(),
     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])


img_to_tensor = transforms.ToTensor()





def train_model(model, train_loader, test_loader, criterion, optimizer, num_epochs):
    for epoch in range(num_epochs):
        model.train()
        running_loss = 0.0
        for batch_idx, (inputs, labels) in enumerate(train_loader):
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

            running_loss += loss.item() * inputs.size(0)

        epoch_loss = running_loss / len(train_loader.dataset)

        model.eval()
        correct = 0
        total = 0
        with torch.no_grad():
            for inputs, labels in test_loader:

                outputs = model(inputs)
                _, predicted = torch.max(outputs, 1)
                total += labels.size(0)
                correct += (predicted == labels).sum().item()

        accuracy = correct / total

        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {accuracy:.2%}')


model3 = PrimarySkinCancerNet()

criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model3.parameters(), lr=0.001)

num_epochs = 10
train_model(model3, train_dataset, val_dataset, criterion, optimizer, num_epochs)

"""# Primary Model V2 training"""

dataset_size = len(data_loader_1.dataset)
train_size = int(0.7 * dataset_size)
val_size = int(0.2*dataset_size)
test_size = int(0.1*dataset_size)

train_dataset_1, val_dataset_1, test_dataset_1 = random_split(data_loader_1.dataset, [train_size, val_size, test_size])
train_dataset_2, val_dataset_2, test_dataset_2 = random_split(data_loader_2.dataset, [train_size, val_size, test_size])
train_dataset_3, val_dataset_3, test_dataset_3 = random_split(data_loader_3.dataset, [train_size, val_size, test_size])


from torch.utils.data import ConcatDataset


train_datasets = [train_dataset_1, train_dataset_2, train_dataset_3]
train_dataset = ConcatDataset(train_datasets)
train_dataset = DataLoader(train_dataset, batch_size=64, shuffle=True)
# for batch_idx, (inputs, targets) in enumerate(train_dataset):
#   print("batch idx:", batch_idx)
#   print("inputs:", inputs)
#   print("targest:", targets)
#   break
del train_dataset_1, train_dataset_2, train_dataset_3


val_datasets = [val_dataset_1, val_dataset_2, val_dataset_3]
val_dataset = ConcatDataset(val_datasets)
val_dataset = DataLoader(val_dataset, batch_size=64, shuffle=True)

del val_dataset_1, val_dataset_2, val_dataset_3


test_datasets = [test_dataset_1, test_dataset_2, test_dataset_3]
test_dataset = ConcatDataset(test_datasets)
test_dataset = DataLoader(test_dataset, batch_size=64, shuffle=True)

del test_dataset_1, test_dataset_2, test_dataset_3



transform = transforms.Compose(
    [transforms.Resize((512, 512)),
    transforms.ToTensor(),
     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])


img_to_tensor = transforms.ToTensor()





def train_model(model, train_loader, test_loader, criterion, optimizer, num_epochs):
    for epoch in range(num_epochs):
        model.train()
        running_loss = 0.0
        for batch_idx, (inputs, labels) in enumerate(train_loader):
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

            running_loss += loss.item() * inputs.size(0)

        epoch_loss = running_loss / len(train_loader.dataset)

        model.eval()
        correct = 0
        total = 0
        with torch.no_grad():
            for inputs, labels in test_loader:

                outputs = model(inputs)
                _, predicted = torch.max(outputs, 1)
                total += labels.size(0)
                print("labels.size(0): ", labels.size(0))
                correct += (predicted == labels).sum().item()

        accuracy = correct / total
        print("correct: ", correct)
        print("total: ", total)
        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {accuracy:.4f}')


model4 = PrimarySkinCancerNet_V2()

criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model4.parameters(), lr=0.005)

num_epochs = 20
train_model(model4, train_dataset, val_dataset, criterion, optimizer, num_epochs)

#nv_dataloader, mel_dataloader, bkl_dataloader, bcc_dataloader, akiec_dataloader, vasc_dataloader, df_dataloader, classes, class_to_idx = ANN_dataloader(data_paths, metadata_file, batch_size=32, shuffle=True, transform = transform)


dataset_size = len(nv_dataloader.dataset)
print(dataset_size)
train_size = 95
val_size = 10
test_size = 10

train_nv, val_nv, test_nv = random_split(nv_dataloader.dataset, [train_size, val_size, test_size])
train_mel, val_mel, test_mel = random_split(mel_dataloader.dataset, [train_size, val_size, test_size])
train_bkl, val_bkl, test_bkl = random_split(bkl_dataloader.dataset, [train_size, val_size, test_size])
train_bcc, val_bcc, test_bcc = random_split(bcc_dataloader.dataset, [train_size, val_size, test_size])
train_akiec, val_akiec, test_akiec = random_split(akiec_dataloader.dataset, [train_size, val_size, test_size])
train_vasc, val_vasc, test_vasc = random_split(vasc_dataloader.dataset, [train_size, val_size, test_size])
train_df, val_df, test_df = random_split(df_dataloader.dataset, [train_size, val_size, test_size])


from torch.utils.data import ConcatDataset

train_datasets = [train_nv, train_mel, train_bkl, train_bcc, train_akiec, train_vasc, train_df]
train_dataset = ConcatDataset(train_datasets)
train_dataset = DataLoader(train_dataset, batch_size=40, shuffle=True)


# for batch_idx, (inputs, targets) in enumerate(train_dataset):
#   print("batch idx:", batch_idx)
#   print("inputs:", inputs)
#   print("targest:", targets)
#   break
del train_nv, train_mel, train_bkl, train_bcc, train_akiec, train_vasc, train_df

val_datasets = [val_nv, val_mel, val_bkl, val_bcc, val_akiec, val_vasc, val_df]
val_dataset = ConcatDataset(val_datasets)
val_dataset = DataLoader(val_dataset, batch_size=40, shuffle=True)

del val_nv, val_mel, val_bkl, val_bcc, val_akiec, val_vasc, val_df

test_datasets = [test_nv, test_mel, test_bkl, test_bcc, test_akiec, test_vasc, test_df]
test_dataset = ConcatDataset(test_datasets)
test_dataset = DataLoader(test_dataset, batch_size=40, shuffle=True)

del test_nv, test_mel, test_bkl, test_bcc, test_akiec, test_vasc, test_df



transform = transforms.Compose(
    [transforms.Resize((512, 512)),
    transforms.ToTensor(),
     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])


img_to_tensor = transforms.ToTensor()





def train_model(model, train_loader, test_loader, criterion, optimizer, num_epochs):
    for epoch in range(num_epochs):
        model.train()
        running_loss = 0.0
        for batch_idx, (inputs, labels) in enumerate(train_loader):
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

            running_loss += loss.item() * inputs.size(0)

        epoch_loss = running_loss / len(train_loader.dataset)

        model.eval()
        correct = 0
        total = 0
        with torch.no_grad():
            for inputs, labels in test_loader:

                outputs = model(inputs)
                _, predicted = torch.max(outputs, 1)
                total += labels.size(0)
                print("labels.size(0): ", labels.size(0))
                correct += (predicted == labels).sum().item()

        accuracy = correct / total
        print("correct: ", correct)
        print("total: ", total)
        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {accuracy:.4f}')


model4 = PrimarySkinCancerNet_V2()

criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model4.parameters(), lr=0.01)

num_epochs = 30
train_model(model4, train_dataset, val_dataset, criterion, optimizer, num_epochs)

"""Plotting for the primary model"""

# train_loss_list = []
# train_accuracy_list = []
# validation_loss = []
# validation_accuracy = []


plt.title("Train vs Validation Loss")
#n = len(train_loss_list)
n = 8
plt.plot(range(1,n+1), train_loss_list[2:], label="Train")
plt.plot(range(1,n+1), validation_loss[2:], label="Validation")
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.legend(loc='best')
plt.show()

plt.title("Train vs Validation Accuracy")
plt.plot(range(1,n+1), train_accuracy_list[2:], label="Train")
plt.plot(range(1,n+1), validation_accuracy[2:], label="Validation")
plt.xlabel("Epoch")
plt.ylabel("Accuracy")
plt.legend(loc='best')
plt.show()

"""----------------------------------------------

### PLOTTING
"""

# train_loss_list = []
# train_accuracy_list = []
# validation_loss = []
# validation_accuracy = []


plt.title("Train vs Validation Loss")
#n = len(train_loss_list)
n = 8
plt.plot(range(1,n+1), train_loss_list[2:], label="Train")
plt.plot(range(1,n+1), validation_loss[2:], label="Validation")
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.legend(loc='best')
plt.show()

plt.title("Train vs Validation Accuracy")
plt.plot(range(1,n+1), train_accuracy_list[2:], label="Train")
plt.plot(range(1,n+1), validation_accuracy[2:], label="Validation")
plt.xlabel("Epoch")
plt.ylabel("Accuracy")
plt.legend(loc='best')
plt.show()

# uses batches, balanced classes

model_1 = Skin_cancer_Net()


train_size = 3
val_size = 1
test_size = 1

#datasets_list = [nv_dataloader, mel_dataloader, bkl_dataloader, bcc_dataloader, akiec_dataloader, vasc_dataloader, df_dataloader]
#dataset = ConcatDataset(datasets_list)

nv_train, nv_val, nv_test = random_split(nv_dataloader, [train_size, val_size, test_size])
mel_train, mel_val, mel_test = random_split(mel_dataloader, [train_size, val_size, test_size])
blk_train, blk_val, blk_test = random_split(bkl_dataloader, [train_size, val_size, test_size])
bcc_train, bcc_val, bcc_test = random_split(bcc_dataloader, [train_size, val_size, test_size])
akiec_train, akiec_val, akiec_test = random_split(akiec_dataloader, [train_size, val_size, test_size])
vasc_train, vasc_val, vasc_test = random_split(vasc_dataloader, [train_size, val_size, test_size])

train_datasets = [nv_train, mel_train, blk_train, bcc_train, akiec_train, vasc_train]
val_datasets = [nv_val, mel_val, blk_val, bcc_val, akiec_val, vasc_val]
test_datasets = [nv_test, mel_test, blk_test, bcc_test, akiec_test, vasc_test]

train_dataset = ConcatDataset(train_datasets)
val_dataset = ConcatDataset(val_datasets)
test_dataset = ConcatDataset(test_datasets)
train_dataset = DataLoader(train_dataset, batch_size=23, shuffle=True)
val_dataset = DataLoader(val_dataset, batch_size=23, shuffle=True)
test_dataset = DataLoader(test_dataset, batch_size=23, shuffle=True)
print(train_dataset.batch_size)
print(val_dataset.batch_size)
print(test_dataset.batch_size)




from torch.utils.data import ConcatDataset


transform = transforms.Compose(
    [transforms.Resize((512, 512)),
    transforms.ToTensor(),
     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])


img_to_tensor = transforms.ToTensor()


criterion = nn.CrossEntropyLoss()
# was originally:
optimizer = optim.SGD(model_1.parameters(), lr=0.01, momentum=0.9)
#optimizer = optim.Adam(model_1.parameters(), lr=0.01)

#print("Before epoch")
#for epoch in range(1):    # line added to test how the number of itterations affects accuracy
#  print("epoch: ", epoch)
i = 0
epochs = 10
train_loss_list = []
train_accuracy_list = []
validation_loss = []
validation_accuracy = []
for i in range(epochs):
  #for (image, label) in train_dataset:
  for batch_idx, (images, labels) in enumerate(train_dataset):


    out = model_1(images)
    loss = criterion(out, labels)
    loss.backward()
    optimizer.step()
    optimizer.zero_grad()


  train_loss = 0
  train_accuracy = 0
  n_imgs = 0
  for batch_idx, (images, label) in enumerate(train_dataset):
      prob = model_1(images)

      max_prob_indices = torch.argmax(prob, dim = 1)

      for i in range(len(max_prob_indices)):
        if max_prob_indices[i].item() == label[i]:
          train_accuracy += 1
        n_imgs += 1


      loss_batch = criterion(prob, label)
      train_loss += loss_batch.item()

  print("Training Loss:", train_loss/n_imgs)
  print("Training Accuracy:", train_accuracy/n_imgs)
  train_loss_list.append(train_loss/n_imgs)
  train_accuracy_list.append(train_accuracy/n_imgs)


  val_loss = 0
  val_accuracy = 0
  n_imgs = 0
  for batch_idx, (images, label) in enumerate(val_dataset):
      prob = model_1(images)

      max_prob_indices = torch.argmax(prob, dim = 1)

      for i in range(len(max_prob_indices)):
        if max_prob_indices[i].item() == label[i]:
          val_accuracy += 1
        n_imgs += 1

      loss_batch = criterion(prob, label)
      val_loss += loss_batch.item()

  print("Validation Loss:", val_loss/n_imgs)
  print("Validation Accuracy:", val_accuracy/n_imgs)
  validation_loss.append(val_loss/n_imgs)
  validation_accuracy.append(val_accuracy/n_imgs)







test_loss = 0
test_accuracy = 0
n_imgs = 0
for batch_idx, (images, label) in enumerate(test_dataset):
    prob = model_1(images)

    max_prob_indices = torch.argmax(prob, dim = 1)

    for i in range(len(max_prob_indices)):
      if max_prob_indices[i].item() == label[i]:
        test_accuracy += 1
      n_imgs += 1

    #compute difference between labels and output probs
    #labels_one_hot = torch.nn.functional.one_hot(labels, num_classes=7).float()

    loss_batch = criterion(prob, label)
    test_loss += loss_batch.item()

print("Test Loss:", test_loss/n_imgs)
print("Test Accuracy:", test_accuracy/n_imgs)

import os

base_path = "/content/gdrive/MyDrive/Sorted_Images"
contents = os.listdir(base_path)
print("Contents of Sorted_Images:", contents)

"""# Re_orginizing data"""

# Final test images back
# AK
# BCC
# BKL
# MEL
# NV

import shutil
import os

source_folder = '/content/drive/MyDrive/Final_test_images/nv'
destination_folder = '/content/drive/MyDrive/Sorted_Images/NV'

os.makedirs(destination_folder, exist_ok=True)

files = os.listdir(source_folder)

for file_name in files:
    source_file = os.path.join(source_folder, file_name)
    destination_file = os.path.join(destination_folder, file_name)
    shutil.move(source_file, destination_file)
    print(f"Moved file: {file_name}")

print("All files have been moved.")

folder_path = '/content/drive/MyDrive/Sorted_Images/BKL'

image_extensions = {'.jpg', '.jpeg', '.png', '.gif', '.bmp', '.tiff', '.webp'}

def count_images(folder_path):
    image_count = 0
    for file_name in os.listdir(folder_path):
        if any(file_name.lower().endswith(ext) for ext in image_extensions):
            image_count += 1
    return image_count

num_images = count_images(folder_path)
print(f"Number of images in the folder: {num_images}")

import pandas as pd

ground_truth_file = '/content/drive/MyDrive/Final_test_images/ISIC_2019_Training_GroundTruth.csv'

ground_truth_df = pd.read_csv(ground_truth_file)

ground_truth_df.head()

source_folder = '/content/drive/MyDrive/Sorted_Images/NV'
destination_folder = '/content/drive/MyDrive/Sorted_Images/AK'

os.makedirs(destination_folder, exist_ok=True)

ak_class_index = ground_truth_df.columns.get_loc('AK')

for index, row in ground_truth_df.iterrows():
    image_id = row['image']
    if row[ak_class_index] == 1:
        source_image_path = os.path.join(source_folder, f'{image_id}.jpg')
        destination_image_path = os.path.join(destination_folder, f'{image_id}.jpg')
        if os.path.exists(source_image_path):
            shutil.move(source_image_path, destination_image_path)
            print(f"Moved {image_id}.jpg to AK_images")

print("All AK images have been moved.")

import os
import shutil
import random

source_folder = '/content/drive/MyDrive/Sorted_Images/NV'
destination_folder = '/content/drive/MyDrive/Final_test_images/nv'

os.makedirs(destination_folder, exist_ok=True)

all_files = os.listdir(source_folder)

image_extensions = {'.jpg', '.jpeg', '.png', '.gif', '.bmp', '.tiff', '.webp'}
image_files = [f for f in all_files if os.path.splitext(f)[1].lower() in image_extensions]

if len(image_files) < 81:
    raise ValueError("Not enough images in the source folder to select 81 randomly.")

selected_images = random.sample(image_files, 81)

for image in selected_images:
    source_image_path = os.path.join(source_folder, image)
    destination_image_path = os.path.join(destination_folder, image)
    shutil.move(source_image_path, destination_image_path)
    print(f"Moved {image} to {destination_folder}")

print("Selected images have been moved.")

"""### Color normalization

"""

!pip install torch torchvision

import torch
from torchvision import transforms

# normalize colors

import cv2
import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler
from glob import glob

def mean_std(image_paths):
    means = []
    stds = []
    count = 0

    for path in image_paths:
        image = cv2.imread(path)
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        image = image / 255.0

        means.append(np.mean(image, axis=(0, 1)))
        stds.append(np.std(image, axis=(0, 1)))
        count +=1
        print(count)

    means = np.mean(means, axis=0)
    stds = np.mean(stds, axis=0)

    return means, stds

sk_akiec_path = "/content/drive/MyDrive/skinCancerData/sorted_images_HAM10000/akiec"
sk_bcc_path = "/content/drive/MyDrive/skinCancerData/sorted_images_HAM10000/bcc"
sk_bkl_path = "/content/drive/MyDrive/skinCancerData/sorted_images_HAM10000/bkl"
sk_mel_path = "/content/drive/MyDrive/skinCancerData/sorted_images_HAM10000/mel"
sk_nv_path = "/content/drive/MyDrive/skinCancerData/sorted_images_HAM10000/nv"

sorted_ak_path = "/content/drive/MyDrive/Sorted_Images/AK"
sorted_bcc_path = "/content/drive/MyDrive/Sorted_Images/BCC"
sorted_bkl_path = "/content/drive/MyDrive/Sorted_Images/BKL"

ft_akiec_path = "/content/drive/MyDrive/Final_test_images/akiec"
ft_bcc_path = "/content/drive/MyDrive/Final_test_images/bcc"
ft_bkl_path = "/content/drive/MyDrive/Final_test_images/bkl"
ft_mel_path = "/content/drive/MyDrive/Final_test_images/mel"
ft_nv_path = "/content/drive/MyDrive/Final_test_images/nv"

#paths = [sk_akiec_path, sk_bcc_path, sk_bkl_path, sk_mel_path, sk_nv_path, sorted_ak_path, sorted_bcc_path, sorted_bkl_path, ft_akiec_path, ft_bcc_path, ft_bkl_path, ft_mel_path, ft_nv_path]

image_name_paths = []


image_names = get_image_names(sk_akiec_path)
for i in image_names:
  image_name_paths.append(os.path.join(sk_akiec_path, i))
print(image_name_paths[0])
sk_akiec_path_mean, sk_akiec_path_std = mean_std(image_name_paths)

print("Mean:", sk_akiec_path_mean)
print("Std:", sk_akiec_path_std)



image_name_paths = []

image_names = get_image_names(sk_bcc_path)
for i in image_names:
  image_name_paths.append(os.path.join(sk_bcc_path, i))
sk_bcc_path_mean, sk_bcc_path_std = mean_std(image_name_paths)

print("Mean:", sk_bcc_path_mean)
print("Std:", sk_bcc_path_std)


image_name_paths = []

image_names = get_image_names(sk_bkl_path)
for i in image_names:
  image_name_paths.append(os.path.join(sk_bkl_path, i))
sk_bkl_path_mean, sk_bkl_path_std = mean_std(image_name_paths)

print("Mean:", sk_bkl_path_mean)
print("Std:", sk_bkl_path_std)

image_name_paths = []


image_names = get_image_names(sk_mel_path)
for i in image_names:
  image_name_paths.append(os.path.join(sk_mel_path, i))
print(image_name_paths[0])
sk_mel_path_mean, sk_mel_path_std = mean_std(image_name_paths)

print("Mean:", sk_mel_path_mean)
print("Std:", sk_mel_path_std)


image_name_paths = []


image_names = get_image_names(sk_nv_path)
for i in image_names:
  image_name_paths.append(os.path.join(sk_nv_path, i))
print(image_name_paths[0])
sk_nv_path_mean, sk_nv_path_std = mean_std(image_name_paths)

print("Mean:", sk_nv_path_mean)
print("Std:", sk_nv_path_std)


image_name_paths = []


image_names = get_image_names(sorted_ak_path)
for i in image_names:
  image_name_paths.append(os.path.join(sorted_ak_path, i))
print(image_name_paths[0])
sorted_ak_path_mean, sorted_ak_path_std = mean_std(image_name_paths)

print("Mean:", sorted_ak_path_mean)
print("Std:", sorted_ak_path_std)



image_name_paths = []


image_names = get_image_names(sorted_bcc_path)
for i in image_names:
  image_name_paths.append(os.path.join(sorted_bcc_path, i))
print(image_name_paths[0])
sorted_bcc_path_mean, sorted_bcc_path_std = mean_std(image_name_paths)

print("Mean:", sorted_bcc_path_mean)
print("Std:", sorted_bcc_path_std)


image_name_paths = []


image_names = get_image_names(sorted_bkl_path)
for i in image_names:
  image_name_paths.append(os.path.join(sorted_bkl_path, i))
print(image_name_paths[0])
sorted_bkl_path_mean, sorted_bkl_path_std = mean_std(image_name_paths)

print("Mean:", sorted_bkl_path_mean)
print("Std:", sorted_bkl_path_std)

image_name_paths = []


image_names = get_image_names(ft_akiec_path)
for i in image_names:
  image_name_paths.append(os.path.join(ft_akiec_path, i))
print(image_name_paths[0])
ft_akiec_path_mean, ft_akiec_path_std = mean_std(image_name_paths)

print("Mean:", ft_akiec_path_mean)
print("Std:", ft_akiec_path_std)


image_name_paths = []


image_names = get_image_names(ft_bcc_path)
for i in image_names:
  image_name_paths.append(os.path.join(ft_bcc_path, i))
print(image_name_paths[0])
ft_bcc_path_mean, ft_bcc_path_std = mean_std(image_name_paths)

print("Mean:", ft_bcc_path_mean)
print("Std:", ft_bcc_path_std)



image_name_paths = []


image_names = get_image_names(ft_bkl_path)
for i in image_names:
  image_name_paths.append(os.path.join(ft_bkl_path, i))
print(image_name_paths[0])
ft_bkl_path_mean, ft_bkl_path_std = mean_std(image_name_paths)

print("Mean:", ft_bkl_path_mean)
print("Std:", ft_bkl_path_std)


image_name_paths = []


image_names = get_image_names(ft_mel_path)
for i in image_names:
  image_name_paths.append(os.path.join(ft_mel_path, i))
print(image_name_paths[0])
ft_mel_path_mean, ft_mel_path_std = mean_std(image_name_paths)

print("Mean:", ft_mel_path_mean)
print("Std:", ft_mel_path_std)



image_name_paths = []


image_names = get_image_names(ft_nv_path)
for i in image_names:
  image_name_paths.append(os.path.join(ft_nv_path, i))
print(image_name_paths[0])
ft_nv_path_mean, ft_nv_path_std = mean_std(image_name_paths)

print("Mean:", ft_nv_path_mean)
print("Std:", ft_nv_path_std)

# sk_akiec_path
# sk_bcc_path
# sk_bkl_path
# sk_mel_path
# sk_nv_path
# sorted_ak_path
# sorted_bcc_path
# sorted_bkl_path
# ft_akiec_path
# ft_bcc_path
# ft_bkl_path
# ft_mel_path
# ft_nv_path

print(sk_akiec_path_mean, sk_akiec_path_std)
print(sk_bcc_path_mean, sk_bcc_path_std)
print(sk_bkl_path_mean, sk_bkl_path_std)
print(sk_mel_path_mean, sk_mel_path_std)
print(sk_nv_path_mean, sk_nv_path_std)
print(sorted_ak_path_mean, sorted_ak_path_std)
print(sorted_bcc_path_mean, sorted_bcc_path_std)
print(sorted_bkl_path_mean, sorted_bkl_path_std)
print(ft_akiec_path_mean, ft_akiec_path_std)
print(ft_bcc_path_mean, ft_bcc_path_std)
print(ft_bkl_path_mean, ft_bkl_path_std)
print(ft_mel_path_mean, ft_mel_path_std)
print(ft_nv_path_mean, ft_nv_path_std)

means = [sk_akiec_path_mean, sk_bcc_path_mean, sk_bkl_path_mean, sk_mel_path_mean, sk_nv_path_mean, sorted_ak_path_mean, sorted_bcc_path_mean, sorted_bkl_path_mean, ft_akiec_path_mean, ft_bcc_path_mean, ft_bkl_path_mean, ft_mel_path_mean, ft_nv_path_mean]
stds = [sk_akiec_path_std, sk_bcc_path_std, sk_bkl_path_std, sk_mel_path_std, sk_nv_path_std, sorted_ak_path_std, sorted_bcc_path_std, sorted_bkl_path_std,ft_akiec_path_std,ft_bcc_path_std,ft_bkl_path_std,ft_mel_path_std, ft_nv_path_std]

mean = [0, 0, 0]
std = [0, 0, 0]
for i in range(len(means)):
  mean[0] += means[i][0]
  mean[1] += means[i][1]
  mean[2] += means[i][2]
  std[0] += stds[i][0]
  std[1] += stds[i][1]
  std[2] += stds[i][2]

mean[0] /= len(means)
mean[1] /= len(means)
mean[2] /= len(means)
std[0] /= len(means)
std[1] /= len(means)
std[2] /= len(means)

print(mean)
print(std)

x = [1, 2, 3]
y = [x]*2
print(y)
z = [[1, 1, 1], [1, 1, 1]]
import numpy as np
y_array = np.array(y)
z_array = np.array(z)
result = y_array - z_array
print(result)

"""# Mean and STD"""

import tensorflow as tf

mean = [0.668064724552625, 0.5319799665857023, 0.5424772260521684]
std = [0.1267589899137812, 0.13991206346123924, 0.1519223498642154]

mean_1 = [mean[0]] * 512
mean_2 = [mean[1]] * 512
mean_3 = [mean[2]] * 512
mean_list = [[mean_1]*512, [mean_2]*512, [mean_3]*512]

std_1 = [std[0]] * 512
std_2 = [std[1]] * 512
std_3 = [std[2]] * 512
std_list = [[std_1]*512, [std_2]*512, [std_3]*512]


#mean_tensor = torch.tensor(mean_list, dtype=torch.float32)
#std_tensor = torch.tensor(std_list, dtype=torch.float32)

mean_array = np.array(mean_list)
std_array = np.array(std_list)

mean_tensor = torch.from_numpy(mean_array)
std_tensor = torch.from_numpy(std_array)


# normalized_image = (image_tensor - mean) / std

# print("Normalized Image Tensor:")
# print(normalized_image)

def color_normalize(image, mean, std):
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    image = image / 255.0
    image = (image - mean) / std
    return image



"""### Dynamic Dataloader: ie. you call it during the train function and it loads one batch at a time"""

# Before the dataloader, this function is used in the data to load each image
def load_image(filename, path, transform):
    img_path = os.path.join(path, filename)
    img = Image.open(img_path).convert('RGB')

    img = transform(img)
    return img

# This function is used before dataloader to get the names of all the images in
# a file

def get_image_names(path):
    image_names = []
    for filename in os.listdir(path):
        if filename.endswith('.jpg'):
            image_names.append(filename)

    return image_names

# Data loader, makes classes even

# Melanocytic nevi (nv): 6705
# Melanoma (mel): 1113
# Benign keratosis-like lesions (bkl): 1099 + 2624 = 3723
# Basal cell carcinoma (bcc): 514 + 3323 = 3837
# Actinic keratoses (akiec): 327 + 867 = 1194

# 1194 - 1113 = 81


# 1113 images per catagory, 5565 total


import os
import pandas as pd
from PIL import Image
from torchvision.transforms import transforms
from torch.utils.data import Dataset, DataLoader

# This function loads data by batchs to not destroy the ram
# image_names_lists is a list of lists. Each sublist contntains the names names
# of all the images in that file

transform = transforms.Compose(
    [transforms.Resize((256, 256)),
    transforms.ToTensor(),
     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])




def Dynamic_dataloader(image_name_lists, batch_number, batch_size=35, shuffle=True, transform = transform):
    # adjust batch size to something divisible by 5
    if batch_size % 5 != 0:
      print("Batch size must be divisible by 5")
      return
    nv_path = "/content/drive/MyDrive/Sorted_Images/NV"
    mel_path = "/content/drive/MyDrive/Sorted_Images/MEL"
    bkl_path = "/content/drive/MyDrive/Sorted_Images/BKL"
    bcc_path = "/content/drive/MyDrive/Sorted_Images/BCC"
    akiec_path = "/content/drive/MyDrive/Sorted_Images/AK"

    nv_one_hot = [1, 0, 0, 0, 0]
    mel_one_hot = [0, 1, 0, 0, 0]
    bkl_one_hot = [0, 0, 1, 0, 0]
    bcc_one_hot = [0, 0, 0, 1, 0]
    akiec_one_hot = [0, 0, 0, 0, 1]

    nv_image_list = image_name_lists[0]
    mel_image_list = image_name_lists[1]
    bkl_image_list = image_name_lists[2]
    bcc_image_list = image_name_lists[3]
    akiec_image_list = image_name_lists[4]


    batch_list = []
    count = 0

    for i in range((batch_number*10), min(1032, (batch_number + 1)*10)):
      # NV
      nv_image = load_image(nv_image_list[i], nv_path, transform)
      nv_image = (nv_image - mean_array) / std_array
      batch_list.append((nv_image.float(), torch.tensor(nv_one_hot)))

      # MEL
      mel_image = load_image(mel_image_list[i], mel_path, transform)
      mel_image = (mel_image - mean_array) / std_array
      batch_list.append((mel_image.float(), torch.tensor(mel_one_hot)))

      # BKL - 1099
      bkl_image = load_image(bkl_image_list[i], bkl_path, transform)
      bkl_image = (bkl_image - mean_array) / std_array
      batch_list.append((bkl_image.float(), torch.tensor(bkl_one_hot)))

      # BCC - 514
      bcc_image = load_image(bcc_image_list[i], bcc_path, transform)
      bcc_image = (bcc_image - mean_array) / std_array
      batch_list.append((bcc_image.float(), torch.tensor(bcc_one_hot)))

      # AKIE - 327
      akiec_image = load_image(akiec_image_list[i], akiec_path, transform)
      akiec_image = (akiec_image - mean_array) / std_array
      batch_list.append((akiec_image.float(), torch.tensor(akiec_one_hot)))

    batch_dataloader = DataLoader(batch_list, batch_size=batch_size, shuffle=shuffle)

    return batch_dataloader

from google.colab import drive
drive.mount('/content/drive')

nv_path = "/content/drive/MyDrive/skinCancerData/sorted_images_HAM10000/nv"

mel_path = "/content/drive/MyDrive/skinCancerData/sorted_images_HAM10000/mel"
bkl_path_1 = "/content/drive/MyDrive/skinCancerData/sorted_images_HAM10000/bkl"
bkl_path_2 = "/content/drive/MyDrive/Sorted_Images/BKL"
bcc_path_1 = "/content/drive/MyDrive/skinCancerData/sorted_images_HAM10000/bcc"
bcc_path_2 = "/content/drive/MyDrive/Sorted_Images/BCC"
akiec_path_1 = "/content/drive/MyDrive/skinCancerData/sorted_images_HAM10000/akiec"
akiec_path_2 = "/content/drive/MyDrive/Sorted_Images/AK"

paths = [nv_path, mel_path, bkl_path_1, bkl_path_2, bcc_path_1, bcc_path_2, akiec_path_1, akiec_path_2]

image_name_lists = []
for path in paths:
  image_name_lists.append(get_image_names(path))
print(len(image_name_lists[3]))

transform = transforms.Compose(
    [transforms.Resize((256, 256)),
    transforms.ToTensor(),
     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])


batch_dataloader = Dynamic_dataloader(image_name_lists, 0, 35, shuffle=False, transform = transform)

for batch_idx, (images, labels) in enumerate(batch_dataloader):
  print(batch_idx)
  print(images.shape)
  print(labels)
#

"""### New Train function using the dynamic dataloader"""

def get_model_name(name, version_number, batch_size, epoch):
    """ Generate a name for the model consisting of all the hyperparameter values

    Args:
        config: Configuration object containing the hyperparameters
    Returns:
        path: A string with the hyperparameter name and value concatenated
    """
    path = "model_{0}_v{1}_bs{2}_epoch{3}".format(name,
                                                   version_number,
                                                   batch_size,
                                                   epoch)
    return path

def train_model(image_name_lists, model, criterion, optimizer, transform, num_epochs, batch_size=35):
    train_loss_list = []
    #train_accuracy_list = []
    #validation_loss = []
    validation_accuracy = []



    for epoch in range(num_epochs):
        model.train()
        running_loss = 0.0

      # Batch size of 35, 32 batches total, 20 in train, 6 in val, 6 in test
      # Batch size of 50: 23 batches total, 16 in train, 4 in val, 3 in test
      # 1113/35 = 32*0.7 = 20

      # batch size of 50, 1500 images, 30 batches, 21, 5, 4

      # 1113*5 = 5565/50 = 112 batches, 80, 16, 16
        #for i in range(16):
        for i in range(80):
          batch_dataloader = Dynamic_dataloader(image_name_lists, i, batch_size, shuffle=True, transform = transform)
          for batch_idx, (images, labels) in enumerate(batch_dataloader):
              print("image:", images.shape)
              images = images.float()
              labels = labels.float()
              optimizer.zero_grad()
              outputs = model(images)
              outputs = outputs.view(-1, 5)

              #labels = labels[0]
              #print("outputs: ", outputs)
              #print("labels: ", labels)
              #print("labels[0]: ", labels[0])
              labels = labels.float()
              loss = criterion(outputs, labels)
              loss.backward()
              optimizer.step()
              running_loss += loss.item() * images.size(0)
              print(i)

        #epoch_loss = running_loss / (20*35)
        epoch_loss = running_loss / (16*50)
        train_loss_list.append(epoch_loss)
        #print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}')

        model.eval()
        correct = 0
        total = 0
        with torch.no_grad():
            for i in range(80, 96):
              batch_dataloader = Dynamic_dataloader(image_name_lists, i, batch_size, shuffle=True, transform = transform)
              for batch_idx, (images, labels) in enumerate(batch_dataloader):
                  outputs = model(images)
                  labels = labels.float()
                  probabilities = torch.softmax(outputs, 1)
                  _, predicted = torch.max(probabilities, 1)
                  total += labels.size(0)
                  # print("labels.size(0): ", labels.size(0))
                  # print("probabilities: ", probabilities)
                  # print("predicted: ", predicted)
                  # print("labels: ", labels)
                  probabilities_list = probabilities.tolist()
                  labels_list = labels.tolist()
                  #print("probabilities_list: ", probabilities_list)
                  #print("labels_list: ", labels_list)
                  for i in range(len(probabilities_list)):
                    if probabilities_list[i].index(max(probabilities_list[i])) == labels_list[i].index(max(labels_list[i])):
                      correct += 1

        accuracy = correct / total
        validation_accuracy.append(accuracy)
        print("correct: ", correct)
        print("total: ", total)
        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {accuracy:.4f}')
        model_path = get_model_name(model.name, "16", batch_size, epoch)
        torch.save(model.state_dict(), model_path)

    return train_loss_list, validation_accuracy

"""### More plotting"""

def plot(loss, accuracy):
  # train_loss_list = []
  # train_accuracy_list = []
  # validation_loss = []
  # validation_accuracy = []


  plt.title("Loss vs. Epoch")
  n = len(loss)
  plt.plot(range(1,n+1), loss, label="Train")
  plt.xlabel("Epoch")
  plt.ylabel("Loss")
  plt.legend(loc='best')
  plt.show()

  plt.title("Accuracy vs. Epoch")
  plt.plot(range(1,n+1), accuracy, label="Train")
  plt.xlabel("Epoch")
  plt.ylabel("Accuracy")
  plt.legend(loc='best')
  plt.show()

def evaluate(image_name_lists, model, criterion, optimizer, transform, batch_size=35):
      model.eval()
      correct = 0
      total = 0

      # Batch size of 35, 32 batches total, 20 in train, 6 in val, 6 in test
      # Batch size of 50: 23 batches total, 16 in train, 4 in val, 3 in test
      # 1113/35 = 32*0.7 = 20
      with torch.no_grad():
          #for i in range(20, 23):
          for i in range(96, 104):
            batch_dataloader = Dynamic_dataloader(image_name_lists, i, batch_size, shuffle=True, transform = transform)
            for batch_idx, (images, labels) in enumerate(batch_dataloader):
                outputs = model(images)
                labels = labels.float()
                probabilities = torch.softmax(outputs, 1)
                _, predicted = torch.max(probabilities, 1)
                total += labels.size(0)
                print("labels.size(0): ", labels.size(0))
                # print("probabilities: ", probabilities)
                # print("predicted: ", predicted)
                # print("labels: ", labels)
                probabilities_list = probabilities.tolist()
                labels_list = labels.tolist()
                for i in range(len(probabilities_list)):
                  if probabilities_list[i].index(max(probabilities_list[i])) == labels_list[i].index(max(labels_list[i])):
                    correct += 1


      #epoch_loss = running_loss / (20*35)

      accuracy = correct / total
      validation_accuracy.append(accuracy)
      print("correct: ", correct)
      print("total: ", total)

      return accuracy

"""# Sorting Data for the final testing part, don't run this again"""

nv_path = "/content/drive/MyDrive/skinCancerData/sorted_images_HAM10000/nv"
mel_path = "/content/drive/MyDrive/skinCancerData/sorted_images_HAM10000/mel"
bkl_path_1 = "/content/drive/MyDrive/skinCancerData/sorted_images_HAM10000/bkl"
bkl_path_2 = "/content/drive/MyDrive/Sorted_Images/BKL"
bcc_path_1 = "/content/drive/MyDrive/skinCancerData/sorted_images_HAM10000/bcc"
bcc_path_2 = "/content/drive/MyDrive/Sorted_Images/BCC"
akiec_path_1 = "/content/drive/MyDrive/skinCancerData/sorted_images_HAM10000/akiec"
akiec_path_2 = "/content/drive/MyDrive/Sorted_Images/AK"

paths = [nv_path, mel_path, bkl_path_1, bkl_path_2, bcc_path_1, bcc_path_2, akiec_path_1, akiec_path_2]

image_name_lists = []
for path in paths:
  image_name_lists.append(get_image_names(path))
print(len(image_name_lists))

nv_names = image_name_lists[0][81:]
bkl_names = image_name_lists[3][81:]
bcc_names = image_name_lists[5][81:]
akiec_names = image_name_lists[7][81:]

import os
import shutil
destination_base_path = '/content/drive/MyDrive/Final_test_images'

os.makedirs(destination_base_path, exist_ok=True)


class_names = ['akiec', 'bcc', 'bkl', 'nv']
file_lists = {
    'akiec': ["/content/drive/MyDrive/Final_test_images", akiec_names],
    'bcc': ["/content/drive/MyDrive/Final_test_images", bcc_names],
    'bkl': ["/content/drive/MyDrive/Final_test_images", bkl_names] ,
    'nv': ['/content/drive/MyDrive/Final_test_images', nv_names]
}


for class_name in class_names:
    class_source_path = file_lists[class_name][0]
    destination_path = os.path.join(destination_base_path, class_name)

    for filename in file_lists[class_name][1]:
        source_file_path = os.path.join(class_source_path, filename)
        destination_file_path = os.path.join(destination_base_path, class_name, filename)

        if os.path.exists(source_file_path):
            shutil.move(source_file_path, destination_file_path)
            print(f"Moved {filename} from {class_source_path} to {destination_file_path}")
        else:
            print(f"File {filename} does not exist in {class_source_path}")

# This function is used before dataloader to get the names of all the images in
# a file

path = "/content/drive/MyDrive/Final_test_images/bcc"

count = 0
for filename in os.listdir(path):
    if filename.endswith('.jpg'):
        count +=1

print(count)

# Data loader, makes classes even

# Melanocytic nevi (nv): 6705
# Melanoma (mel): 1113
# Benign keratosis-like lesions (bkl): 1099 + 2624 = 3723
# Basal cell carcinoma (bcc): 514 + 3323 = 3837
# Actinic keratoses (akiec): 327 + 867 = 1194

# 1194 - 1113 = 81


# 1113 images per catagory, 5565 total

# get a list of all the images in each of the folders in final_test_images
# take out the first 81
# move the rest to a new folder

akiec_images = get_image_names("/content/drive/MyDrive/Final_test_images/akiec")
bcc_images = get_image_names("/content/drive/MyDrive/Final_test_images/bcc")
bkl_images = get_image_names("/content/drive/MyDrive/Final_test_images/bkl")
nv_images = get_image_names("/content/drive/MyDrive/Final_test_images/nv")

new_akiec_images = akiec_images[81:]
new_bcc_images = bcc_images[81:]
new_bkl_images = bkl_images[81:]
new_nv_images = nv_images[81:]



destination_base_path = '/content/drive/MyDrive/Final_test_images'

os.makedirs(destination_base_path, exist_ok=True)


class_names = ['akiec', 'bcc', 'bkl', 'nv']
file_lists = {
    'akiec': ["/content/drive/MyDrive/Final_test_images/akiec", new_akiec_images, "/content/drive/MyDrive/Sorted_Images/AK"],
    'bcc': ["/content/drive/MyDrive/Final_test_images/bcc", new_bcc_images, "/content/drive/MyDrive/Sorted_Images/BCC"],
    'bkl': ["/content/drive/MyDrive/Final_test_images/bkl", new_bkl_images, "/content/drive/MyDrive/Sorted_Images/BKL"] ,
    'nv': ['/content/drive/MyDrive/Final_test_images/nv', new_nv_images, "/content/drive/MyDrive/skinCancerData/sorted_images_HAM10000/nv"]
}


for class_name in class_names:
    class_source_path = file_lists[class_name][0]
    destination_path = os.path.join(destination_base_path, class_name)

    for filename in file_lists[class_name][1]:
        source_file_path = os.path.join(class_source_path, filename)
        destination_file_path = os.path.join(file_lists[class_name][2], filename)
        if os.path.exists(source_file_path):
            shutil.move(source_file_path, destination_file_path)
            print(f"Moved {filename} from {class_source_path} to {destination_file_path}")
        else:
            print(f"File {filename} does not exist in {class_source_path}")

"""# Training the Baseline model"""

model_0 = Skin_cancer_Net()

nv_path = "/content/drive/MyDrive/Sorted_Images/NV"
mel_path = "/content/drive/MyDrive/Sorted_Images/MEL"
bkl_path = "/content/drive/MyDrive/Sorted_Images/BKL"
bcc_path = "/content/drive/MyDrive/Sorted_Images/BCC"
akiec_path = "/content/drive/MyDrive/Sorted_Images/AK"

#paths = [nv_path, mel_path, bkl_path_1, bkl_path_2, bcc_path_1, bcc_path_2, akiec_path_1, akiec_path_2]
paths = [nv_path, mel_path, bkl_path, bcc_path, akiec_path]
image_name_lists = []
for path in paths:
  image_name_lists.append(get_image_names(path))




transform0 = transforms.Compose(
    [transforms.Resize((512, 512)),
    transforms.ToTensor(),
     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])

criterion0 = nn.CrossEntropyLoss()
optimizer0 = optim.Adam(model_0.parameters(), lr=0.005)

num_epochs = 10
loss, accuracy = train_model(image_name_lists, model_0, criterion0, optimizer0, transform0, num_epochs, batch_size=35)

plot(loss, accuracy)

# PrimarySkinCancerNet_V3 is the same as V2 but has 5 outputs, not 7

model5 = PrimarySkinCancerNet_V3()


nv_path = "/content/gdrive/MyDrive/skinCancerData/sorted_images_HAM10000/nv"
mel_path = "/content/gdrive/MyDrive/skinCancerData/sorted_images_HAM10000/mel"
bkl_path_1 = "/content/gdrive/MyDrive/skinCancerData/sorted_images_HAM10000/bkl"
bkl_path_2 = "/content/gdrive/MyDrive/Sorted_Images/BKL"
bcc_path_1 = "/content/gdrive/MyDrive/skinCancerData/sorted_images_HAM10000/bcc"
bcc_path_2 = "/content/gdrive/MyDrive/Sorted_Images/BCC"
akiec_path_1 = "/content/gdrive/MyDrive/skinCancerData/sorted_images_HAM10000/akiec"
akiec_path_2 = "/content/gdrive/MyDrive/Sorted_Images/AK"

paths = [nv_path, mel_path, bkl_path_1, bkl_path_2, bcc_path_1, bcc_path_2, akiec_path_1, akiec_path_2]

image_name_lists = []
for path in paths:
  image_name_lists.append(get_image_names(path))
print(len(image_name_lists[3]))



transform5 = transforms.Compose(
    [transforms.Resize((256, 256)),
    transforms.ToTensor(),
     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])

criterion5 = nn.CrossEntropyLoss()
optimizer5 = optim.Adam(model5.parameters(), lr=0.005)

num_epochs = 10

train_loss_list, validation_accuracy = train_model(image_name_lists, model5, criterion5, optimizer5, transform5, num_epochs, batch_size=35)

plot(train_loss_list, validation_accuracy)

# PrimarySkinCancerNet_V3 is the same as V2 but has 5 outputs, not 7

model6 = PrimarySkinCancerNet_V3()


nv_path = "/content/gdrive/MyDrive/skinCancerData/sorted_images_HAM10000/nv"
mel_path = "/content/gdrive/MyDrive/skinCancerData/sorted_images_HAM10000/mel"
bkl_path_1 = "/content/gdrive/MyDrive/skinCancerData/sorted_images_HAM10000/bkl"
bkl_path_2 = "/content/gdrive/MyDrive/Sorted_Images/BKL"
bcc_path_1 = "/content/gdrive/MyDrive/skinCancerData/sorted_images_HAM10000/bcc"
bcc_path_2 = "/content/gdrive/MyDrive/Sorted_Images/BCC"
akiec_path_1 = "/content/gdrive/MyDrive/skinCancerData/sorted_images_HAM10000/akiec"
akiec_path_2 = "/content/gdrive/MyDrive/Sorted_Images/AK"

paths = [nv_path, mel_path, bkl_path_1, bkl_path_2, bcc_path_1, bcc_path_2, akiec_path_1, akiec_path_2]

image_name_lists = []
for path in paths:
  image_name_lists.append(get_image_names(path))



transform6 = transforms.Compose(
    [transforms.Resize((256, 256)),
    transforms.ToTensor(),
     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])

criterion6 = nn.CrossEntropyLoss()
optimizer6 = optim.Adam(model6.parameters(), lr=0.001)

num_epochs = 45

train_loss_list, validation_accuracy = train_model(image_name_lists, model6, criterion6, optimizer6, transform6, num_epochs, batch_size=35)
plot(train_loss_list, validation_accuracy)

# PrimarySkinCancerNet_V3 is the same as V2 but has 5 outputs, not 7

model7 = PrimarySkinCancerNet_V3()


nv_path = "/content/gdrive/MyDrive/skinCancerData/sorted_images_HAM10000/nv"

mel_path = "/content/gdrive/MyDrive/skinCancerData/sorted_images_HAM10000/mel"
bkl_path_1 = "/content/gdrive/MyDrive/skinCancerData/sorted_images_HAM10000/bkl"
bkl_path_2 = "/content/gdrive/MyDrive/Sorted_Images/BKL"
bcc_path_1 = "/content/gdrive/MyDrive/skinCancerData/sorted_images_HAM10000/bcc"
bcc_path_2 = "/content/gdrive/MyDrive/Sorted_Images/BCC"
akiec_path_1 = "/content/gdrive/MyDrive/skinCancerData/sorted_images_HAM10000/akiec"
akiec_path_2 = "/content/gdrive/MyDrive/Sorted_Images/AK"

paths = [nv_path, mel_path, bkl_path_1, bkl_path_2, bcc_path_1, bcc_path_2, akiec_path_1, akiec_path_2]

image_name_lists = []
for path in paths:
  image_name_lists.append(get_image_names(path))



transform7 = transforms.Compose(
    [transforms.Resize((512, 512)),
    transforms.ToTensor(),
     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])

criterion7 = nn.CrossEntropyLoss()
#optimizer7 = optim.Adam(model6.parameters(), lr=0.001)
optimizer7 = optim.SGD(model7.parameters(), lr=0.001, momentum=0.5)

num_epochs = 45

train_loss_list, validation_accuracy = train_model(image_name_lists, model7, criterion7, optimizer7, transform7, num_epochs, batch_size=50)
plot(train_loss_list, validation_accuracy)

print(evaluate(image_name_lists, model7, criterion7, optimizer7, transform7, batch_size = 50))

model8 = PrimarySkinCancerNet_V4()


nv_path = "/content/gdrive/MyDrive/skinCancerData/sorted_images_HAM10000/nv"
mel_path = "/content/gdrive/MyDrive/skinCancerData/sorted_images_HAM10000/mel"
bkl_path_1 = "/content/gdrive/MyDrive/skinCancerData/sorted_images_HAM10000/bkl"
bkl_path_2 = "/content/gdrive/MyDrive/Sorted_Images/BKL"
bcc_path_1 = "/content/gdrive/MyDrive/skinCancerData/sorted_images_HAM10000/bcc"
bcc_path_2 = "/content/gdrive/MyDrive/Sorted_Images/BCC"
akiec_path_1 = "/content/gdrive/MyDrive/skinCancerData/sorted_images_HAM10000/akiec"
akiec_path_2 = "/content/gdrive/MyDrive/Sorted_Images/AK"

paths = [nv_path, mel_path, bkl_path_1, bkl_path_2, bcc_path_1, bcc_path_2, akiec_path_1, akiec_path_2]

image_name_lists = []
for path in paths:
  image_name_lists.append(get_image_names(path))




transform8 = transforms.Compose(
    [transforms.Resize((512, 512)),
    transforms.ToTensor(),
     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])

criterion8 = nn.CrossEntropyLoss()
#optimizer7 = optim.Adam(model6.parameters(), lr=0.001)
optimizer8 = optim.SGD(model8.parameters(), lr=0.001, momentum=0.5)

num_epochs = 45

train_loss_list, validation_accuracy = train_model(image_name_lists, model8, criterion8, optimizer8, transform8, num_epochs, batch_size=35)
plot(train_loss_list, validation_accuracy)



model9 = PrimarySkinCancerNet_V4()


nv_path = "/content/gdrive/MyDrive/skinCancerData/sorted_images_HAM10000/nv"
mel_path = "/content/gdrive/MyDrive/skinCancerData/sorted_images_HAM10000/mel"
bkl_path_1 = "/content/gdrive/MyDrive/skinCancerData/sorted_images_HAM10000/bkl"
bkl_path_2 = "/content/gdrive/MyDrive/Sorted_Images/BKL"
bcc_path_1 = "/content/gdrive/MyDrive/skinCancerData/sorted_images_HAM10000/bcc"
bcc_path_2 = "/content/gdrive/MyDrive/Sorted_Images/BCC"
akiec_path_1 = "/content/gdrive/MyDrive/skinCancerData/sorted_images_HAM10000/akiec"
akiec_path_2 = "/content/gdrive/MyDrive/Sorted_Images/AK"

paths = [nv_path, mel_path, bkl_path_1, bkl_path_2, bcc_path_1, bcc_path_2, akiec_path_1, akiec_path_2]

image_name_lists = []
for path in paths:
  image_name_lists.append(get_image_names(path))




transform9 = transforms.Compose(
    [transforms.Resize((512, 512)),
    transforms.ToTensor(),
     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])

criterion9 = nn.CrossEntropyLoss()
optimizer9 = optim.Adam(model9.parameters(), lr=0.001)
#optimizer9 = optim.SGD(model8.parameters(), lr=0.01, momentum=0.5)

num_epochs = 45

train_loss_list, validation_accuracy = train_model(image_name_lists, model9, criterion9, optimizer9, transform9, num_epochs, batch_size=35)
plot(train_loss_list, validation_accuracy)

model10 = PrimarySkinCancerNet_V4()


nv_path = "/content/gdrive/MyDrive/skinCancerData/sorted_images_HAM10000/nv"
mel_path = "/content/gdrive/MyDrive/skinCancerData/sorted_images_HAM10000/mel"
bkl_path_1 = "/content/gdrive/MyDrive/skinCancerData/sorted_images_HAM10000/bkl"
bkl_path_2 = "/content/gdrive/MyDrive/Sorted_Images/BKL"
bcc_path_1 = "/content/gdrive/MyDrive/skinCancerData/sorted_images_HAM10000/bcc"
bcc_path_2 = "/content/gdrive/MyDrive/Sorted_Images/BCC"
akiec_path_1 = "/content/gdrive/MyDrive/skinCancerData/sorted_images_HAM10000/akiec"
akiec_path_2 = "/content/gdrive/MyDrive/Sorted_Images/AK"

paths = [nv_path, mel_path, bkl_path_1, bkl_path_2, bcc_path_1, bcc_path_2, akiec_path_1, akiec_path_2]

image_name_lists = []
for path in paths:
  image_name_lists.append(get_image_names(path))




transform10 = transforms.Compose(
    [transforms.Resize((512, 512)),
    transforms.ToTensor(),
     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])

criterion10 = nn.CrossEntropyLoss()
optimizer10 = optim.Adam(model10.parameters(), lr=0.005)
#optimizer9 = optim.SGD(model8.parameters(), lr=0.01, momentum=0.5)

num_epochs = 45

train_loss_list, validation_accuracy = train_model(image_name_lists, model10, criterion10, optimizer10, transform10, num_epochs, batch_size=35)
plot(train_loss_list, validation_accuracy)

# I changed the batch size here to 50

model11 = PrimarySkinCancerNet_V4()


nv_path = "/content/drive/MyDrive/skinCancerData/sorted_images_HAM10000/nv"
mel_path = "/content/drive/MyDrive/skinCancerData/sorted_images_HAM10000/mel"
bkl_path_1 = "/content/drive/MyDrive/skinCancerData/sorted_images_HAM10000/bkl"
bkl_path_2 = "/content/drive/MyDrive/Sorted_Images/BKL"
bcc_path_1 = "/content/drive/MyDrive/skinCancerData/sorted_images_HAM10000/bcc"
bcc_path_2 = "/content/drive/MyDrive/Sorted_Images/BCC"
akiec_path_1 = "/content/drive/MyDrive/skinCancerData/sorted_images_HAM10000/akiec"
akiec_path_2 = "/content/drive/MyDrive/Sorted_Images/AK"

paths = [nv_path, mel_path, bkl_path_1, bkl_path_2, bcc_path_1, bcc_path_2, akiec_path_1, akiec_path_2]

image_name_lists = []
for path in paths:
  image_name_lists.append(get_image_names(path))




transform11 = transforms.Compose(
    [transforms.Resize((512, 512)),
    transforms.ToTensor(),
     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])

criterion11 = nn.CrossEntropyLoss()
optimizer11 = optim.Adam(model11.parameters(), lr=0.005)
#optimizer9 = optim.SGD(model8.parameters(), lr=0.01, momentum=0.5)

num_epochs = 45

train_loss_list, validation_accuracy = train_model(image_name_lists, model11, criterion11, optimizer11, transform11, num_epochs, batch_size=50)
plot(train_loss_list, validation_accuracy)

# I changed the batch size here to 50

model12 = PrimarySkinCancerNet_V5()


nv_path = "/content/drive/MyDrive/skinCancerData/sorted_images_HAM10000/nv"
mel_path = "/content/drive/MyDrive/skinCancerData/sorted_images_HAM10000/mel"
bkl_path_1 = "/content/drive/MyDrive/skinCancerData/sorted_images_HAM10000/bkl"
bkl_path_2 = "/content/drive/MyDrive/Sorted_Images/BKL"
bcc_path_1 = "/content/drive/MyDrive/skinCancerData/sorted_images_HAM10000/bcc"
bcc_path_2 = "/content/drive/MyDrive/Sorted_Images/BCC"
akiec_path_1 = "/content/drive/MyDrive/skinCancerData/sorted_images_HAM10000/akiec"
akiec_path_2 = "/content/drive/MyDrive/Sorted_Images/AK"

paths = [nv_path, mel_path, bkl_path_1, bkl_path_2, bcc_path_1, bcc_path_2, akiec_path_1, akiec_path_2]

image_name_lists = []
for path in paths:
  image_name_lists.append(get_image_names(path))




transform12 = transforms.Compose(
    [transforms.Resize((512, 512)),
    transforms.ToTensor(),
     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])

criterion12 = nn.CrossEntropyLoss()
#optimizer12 = optim.Adam(model12.parameters(), lr=0.05)
optimizer12 = optim.SGD(model12.parameters(), lr=0.01, momentum=0.5)

num_epochs = 45

train_loss_list, validation_accuracy = train_model(image_name_lists, model12, criterion12, optimizer12, transform12, num_epochs, batch_size=50)
plot(train_loss_list, validation_accuracy)

"""# Gaurika Training with scheduler

"""

def train_model(image_name_lists, model, criterion, optimizer, scheduler, transform, num_epochs, batch_size=35):
    train_loss_list = []

    validation_accuracy = []



    for epoch in range(num_epochs):
        model.train()
        running_loss = 0.0
        for i in range(16):
          batch_dataloader = Dynamic_dataloader(image_name_lists, i, batch_size, shuffle=True, transform = transform)
          for batch_idx, (images, labels) in enumerate(batch_dataloader):
              optimizer.zero_grad()
              outputs = model(images)

              labels = labels.float()
              loss = criterion(outputs, labels)
              loss.backward()
              optimizer.step()
              running_loss += loss.item() * images.size(0)

        epoch_loss = running_loss / (16*50)
        train_loss_list.append(epoch_loss)

        model.eval()
        correct = 0
        total = 0
        with torch.no_grad():
            for i in range(16, 20):
              batch_dataloader = Dynamic_dataloader(image_name_lists, i, batch_size, shuffle=True, transform = transform)
              for batch_idx, (images, labels) in enumerate(batch_dataloader):
                  outputs = model(images)
                  labels = labels.float()
                  probabilities = torch.softmax(outputs, 1)
                  _, predicted = torch.max(probabilities, 1)
                  total += labels.size(0)

                  probabilities_list = probabilities.tolist()
                  labels_list = labels.tolist()

                  for i in range(len(probabilities_list)):
                    if probabilities_list[i].index(max(probabilities_list[i])) == labels_list[i].index(max(labels_list[i])):
                      correct += 1

        accuracy = correct / total
        validation_accuracy.append(accuracy)
        scheduler.step()
        print("correct: ", correct)
        print("total: ", total)
        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {accuracy:.4f}')

    return train_loss_list, validation_accuracy

"""#Gaurika Model in progress"""

# I changed the batch size here to 45, highest accuracy here is 59%

model13 = PrimarySkinCancerNet_V5()


nv_path = "/content/drive/MyDrive/skinCancerData/sorted_images_HAM10000/nv"
mel_path = "/content/drive/MyDrive/skinCancerData/sorted_images_HAM10000/mel"
bkl_path_1 = "/content/drive/MyDrive/skinCancerData/sorted_images_HAM10000/bkl"
bkl_path_2 = "/content/drive/MyDrive/Sorted_Images/BKL"
bcc_path_1 = "/content/drive/MyDrive/skinCancerData/sorted_images_HAM10000/bcc"
bcc_path_2 = "/content/drive/MyDrive/Sorted_Images/BCC"
akiec_path_1 = "/content/drive/MyDrive/skinCancerData/sorted_images_HAM10000/akiec"
akiec_path_2 = "/content/drive/MyDrive/Sorted_Images/AK"

paths = [nv_path, mel_path, bkl_path_1, bkl_path_2, bcc_path_1, bcc_path_2, akiec_path_1, akiec_path_2]

image_name_lists = []
for path in paths:
  image_name_lists.append(get_image_names(path))




transform13 = transforms.Compose([
    transforms.Resize((512, 512)),
    transforms.RandomHorizontalFlip(),
    transforms.RandomVerticalFlip(),
    transforms.RandomRotation(20),
    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),
    transforms.ToTensor(),
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
])


criterion13 = nn.CrossEntropyLoss()
#optimizer12 = optim.Adam(model12.parameters(), lr=0.05)
optimizer13 = optim.SGD(model13.parameters(), lr=0.01, momentum=0.9, weight_decay=1e-4)
scheduler13 = optim.lr_scheduler.StepLR(optimizer13, step_size=10, gamma=0.1)

num_epochs = 45

train_loss_list, validation_accuracy = train_model(image_name_lists, model13, criterion13, optimizer13, scheduler13, transform13, num_epochs, batch_size=50)
plot(train_loss_list, validation_accuracy)

"""# Sarah Model Training Best"""

# I changed the batch size here to 50

model14 = PrimarySkinCancerNet_V6()


nv_path = "/content/drive/MyDrive/skinCancerData/sorted_images_HAM10000/nv"
mel_path = "/content/drive/MyDrive/skinCancerData/sorted_images_HAM10000/mel"
bkl_path_1 = "/content/drive/MyDrive/skinCancerData/sorted_images_HAM10000/bkl"
bkl_path_2 = "/content/drive/MyDrive/Sorted_Images/BKL"
bcc_patAh_1 = "/content/drive/MyDrive/skinCancerData/sorted_images_HAM10000/bcc"
bcc_path_2 = "/content/drive/MyDrive/Sorted_Images/BCC"
akiec_path_1 = "/content/drive/MyDrive/skinCancerData/sorted_images_HAM10000/akiec"
akiec_path_2 = "/content/drive/MyDrive/Sorted_Images/AK"

paths = [nv_path, mel_path, bkl_path_1, bkl_path_2, bcc_path_1, bcc_path_2, akiec_path_1, akiec_path_2]

image_name_lists = []
for path in paths:
  image_name_lists.append(get_image_names(path))




transform14 = transforms.Compose(
    [transforms.Resize((512, 512)),
    transforms.ToTensor(),
     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])

criterion14 = nn.CrossEntropyLoss()
#optimizer14 = optim.Adam(model14.parameters(), lr=0.05)
#optimizer14 = optim.RMSprop(model14.parameters(), lr=0.001, weight_decay=1e-4)
#optimizer14 = optim.LBFGS(model14.parameters(), lr=0.01) # need to add closure to training for this

optimizer14 = optim.SGD(model14.parameters(), lr=0.01, momentum=0.5, weight_decay = 1e-4) # best so far

num_epochs = 35

train_loss_list, validation_accuracy = train_model(image_name_lists, model14, criterion14, optimizer14, transform14, num_epochs, batch_size=50)
plot(train_loss_list, validation_accuracy)

"""# Sarah Model Optimizer = LBFGS

"""

def train_model(image_name_lists, model, criterion, optimizer, transform, num_epochs, batch_size=35):
    train_loss_list = []
    validation_accuracy = []

    for epoch in range(num_epochs):
        model.train()
        running_loss = 0.0

        for i in range(16):
            batch_dataloader = Dynamic_dataloader(image_name_lists, i, batch_size, shuffle=True, transform=transform)
            for batch_idx, (images, labels) in enumerate(batch_dataloader):
                labels = labels.float()

                def closure():
                    optimizer.zero_grad()
                    outputs = model(images)
                    loss = criterion(outputs, labels)
                    loss.backward()
                    return loss

                loss = optimizer.step(closure)
                running_loss += loss.item() * images.size(0)

        epoch_loss = running_loss / (16 * batch_size)
        train_loss_list.append(epoch_loss)

        model.eval()
        correct = 0
        total = 0
        with torch.no_grad():
            for i in range(16, 20):
                batch_dataloader = Dynamic_dataloader(image_name_lists, i, batch_size, shuffle=True, transform=transform)
                for batch_idx, (images, labels) in enumerate(batch_dataloader):
                    labels = labels.long()

                    outputs = model(images)
                    _, predicted = torch.max(outputs, 1)
                    total += labels.size(0)

                    print(type(predicted))
                    print(type(labels))
                    print("Predicted:", predicted.shape)
                    print("Label:", labels.shape)
                    correct += (predicted == labels).sum().item()

        accuracy = correct / total
        validation_accuracy.append(accuracy)
        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {accuracy:.4f}')

    return train_loss_list, validation_accuracy

model15 = PrimarySkinCancerNet_V6()

nv_path = "/content/drive/MyDrive/skinCancerData/sorted_images_HAM10000/nv"
mel_path = "/content/drive/MyDrive/skinCancerData/sorted_images_HAM10000/mel"
bkl_path_1 = "/content/drive/MyDrive/skinCancerData/sorted_images_HAM10000/bkl"
bkl_path_2 = "/content/drive/MyDrive/Sorted_Images/BKL"
bcc_path_1 = "/content/drive/MyDrive/skinCancerData/sorted_images_HAM10000/bcc"
bcc_path_2 = "/content/drive/MyDrive/Sorted_Images/BCC"
akiec_path_1 = "/content/drive/MyDrive/skinCancerData/sorted_images_HAM10000/akiec"
akiec_path_2 = "/content/drive/MyDrive/Sorted_Images/AK"

paths = [nv_path, mel_path, bkl_path_1, bkl_path_2, bcc_path_1, bcc_path_2, akiec_path_1, akiec_path_2]

image_name_lists = []
for path in paths:
    image_name_lists.append(get_image_names(path))

transform15 = transforms.Compose([
    transforms.Resize((512, 512)),
    transforms.ToTensor(),
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
])

criterion15 = nn.CrossEntropyLoss()
optimizer15 = optim.LBFGS(model15.parameters(), lr=0.01)

num_epochs = 10
train_loss_list, validation_accuracy = train_model(image_name_lists, model15, criterion15, optimizer15, transform15, num_epochs, batch_size=50)

plot(train_loss_list, validation_accuracy)

"""# Gaurika + Sarah Combined"""

#gaurika + sarah, using sarah's model
#using gaurika's training

model16 = PrimarySkinCancerNet_V6()


nv_path = "/content/drive/MyDrive/skinCancerData/sorted_images_HAM10000/nv"
mel_path = "/content/drive/MyDrive/skinCancerData/sorted_images_HAM10000/mel"
bkl_path_1 = "/content/drive/MyDrive/skinCancerData/sorted_images_HAM10000/bkl"
bkl_path_2 = "/content/drive/MyDrive/Sorted_Images/BKL"
bcc_path_1 = "/content/drive/MyDrive/skinCancerData/sorted_images_HAM10000/bcc"
bcc_path_2 = "/content/drive/MyDrive/Sorted_Images/BCC"
akiec_path_1 = "/content/drive/MyDrive/skinCancerData/sorted_images_HAM10000/akiec"
akiec_path_2 = "/content/drive/MyDrive/Sorted_Images/AK"

paths = [nv_path, mel_path, bkl_path_1, bkl_path_2, bcc_path_1, bcc_path_2, akiec_path_1, akiec_path_2]

image_name_lists = []
for path in paths:
  image_name_lists.append(get_image_names(path))




transform16 = transforms.Compose([
    transforms.Resize((512, 512)),
    transforms.RandomHorizontalFlip(),
    transforms.RandomVerticalFlip(),
    transforms.RandomRotation(20),
    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),
    transforms.ToTensor(),
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
])

criterion16 = nn.CrossEntropyLoss()
#optimizer12 = optim.Adam(model12.parameters(), lr=0.05)
optimizer16 = optim.SGD(model16.parameters(), lr=0.01, momentum=0.9, weight_decay=1e-4)
#gaurika: play around with scheduler to prevent overfitting/leveling out
scheduler16 = optim.lr_scheduler.StepLR(optimizer16, step_size=10, gamma=0.1)

num_epochs = 35

train_loss_list, validation_accuracy = train_model(image_name_lists, model16, criterion16, optimizer16, scheduler16, transform16, num_epochs, batch_size=50)
plot(train_loss_list, validation_accuracy)

"""# Model 16"""

# I changed the batch size here to 50

model16 = PrimarySkinCancerNet_V7()


nv_path = "/content/drive/MyDrive/Sorted_Images/NV"
mel_path = "/content/drive/MyDrive/Sorted_Images/MEL"
bkl_path = "/content/drive/MyDrive/Sorted_Images/BKL"
bcc_path = "/content/drive/MyDrive/Sorted_Images/BCC"
akiec_path = "/content/drive/MyDrive/Sorted_Images/AK"

#paths = [nv_path, mel_path, bkl_path_1, bkl_path_2, bcc_path_1, bcc_path_2, akiec_path_1, akiec_path_2]

paths = [nv_path, mel_path, bkl_path, bcc_path, akiec_path]
image_name_lists = []
for path in paths:
  image_name_lists.append(get_image_names(path))







transform16 = transforms.Compose(
    [transforms.Resize((512, 512)),
    transforms.ToTensor(),
     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])

criterion16 = nn.CrossEntropyLoss()
#optimizer16 = optim.Adam(model16.parameters(), lr=0.05)
#optimizer16 = optim.RMSprop(model16.parameters(), lr=0.001, weight_decay=1e-4)
#optimizer16 = optim.LBFGS(model16.parameters(), lr=0.01) # need to add closure to training for this

optimizer16 = optim.SGD(model16 .parameters(), lr=0.01, momentum=0.5, weight_decay = 1e-4) # best so far

num_epochs = 49

train_loss_list, validation_accuracy = train_model(image_name_lists, model16 , criterion16, optimizer16, transform16, num_epochs, batch_size=50)
plot(train_loss_list, validation_accuracy)

"""# Testing on completly new data"""

# Final model loading

final_model = PrimarySkinCancerNet_V7()
model_path = get_model_name(final_model.name, "16", 50, epoch=33)
state = torch.load(model_path)
final_model.load_state_dict(state)

# Data loader for final test
transform = transforms.Compose(
    [transforms.Resize((256, 256)),
    transforms.ToTensor(),
     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])

def final_test_dataloader(image_name_lists, count, batch_size=50, shuffle=True, transform = transform):

    # paths
    nv_path = "/content/drive/MyDrive/Final_test_images/nv"
    mel_path = "/content/drive/MyDrive/Final_test_images/mel"
    bkl_path = "/content/drive/MyDrive/Final_test_images/bkl"
    bcc_path = "/content/drive/MyDrive/Final_test_images/bcc"
    akiec_path = "/content/drive/MyDrive/Final_test_images/akiec"


    nv_one_hot = [1, 0, 0, 0, 0]
    mel_one_hot = [0, 1, 0, 0, 0]
    bkl_one_hot = [0, 0, 1, 0, 0]
    bcc_one_hot = [0, 0, 0, 1, 0]
    akiec_one_hot = [0, 0, 0, 0, 1]

    nv_image_list = image_name_lists[0][:81]
    mel_image_list = image_name_lists[1][:81]
    bkl_image_list = image_name_lists[2][:81]
    bcc_image_list = image_name_lists[3][:81]
    akiec_image_list = image_name_lists[4][:81]


    batch_list = []
    #9 of each class at a time
    for i in range((count*10), min(((count + 1)*10), 81)):
      # NV
      nv_image = load_image(nv_image_list[i], nv_path, transform)
      nv_image = (nv_image - mean_array) / std_array
      batch_list.append((nv_image.float(), torch.tensor(nv_one_hot)))

      # MEL
      mel_image = load_image(mel_image_list[i], mel_path, transform)
      mel_image = (mel_image - mean_array) / std_array
      batch_list.append((mel_image.float(), torch.tensor(mel_one_hot)))

      # BKL - 1099
      bkl_image = load_image(bkl_image_list[i], bkl_path, transform)
      bkl_image = (bkl_image - mean_array) / std_array
      batch_list.append((bkl_image.float(), torch.tensor(bkl_one_hot)))

      # BCC - 514
      bcc_image = load_image(bcc_image_list[i], bcc_path, transform)
      bcc_image = (bcc_image - mean_array) / std_array
      batch_list.append((bcc_image.float(), torch.tensor(bcc_one_hot)))

      # AKIE - 327
      akiec_image = load_image(akiec_image_list[i], akiec_path, transform)
      akiec_image = (akiec_image - mean_array) / std_array
      batch_list.append((akiec_image.float(), torch.tensor(akiec_one_hot)))

    batch_dataloader = DataLoader(batch_list, batch_size=batch_size, shuffle=shuffle)

    return batch_dataloader

def false_negative_test (model, criterion, optimizer, transform):
  model.eval()
  accuracy = []


  nv_path = "/content/drive/MyDrive/Final_test_images/nv"
  mel_path = "/content/drive/MyDrive/Final_test_images/mel"
  bkl_path = "/content/drive/MyDrive/Final_test_images/bkl"
  bcc_path = "/content/drive/MyDrive/Final_test_images/bcc"
  akiec_path = "/content/drive/MyDrive/Final_test_images/akiec"

  paths = [nv_path, mel_path, bkl_path, bcc_path, akiec_path]
  class_list = ["nv", "mel", "bkl", "bcc", "akiec"]

  image_name_lists = []
  for path in paths:
    image_name_lists.append(get_image_names(path))


  with torch.no_grad():
      for i in range(len(class_list)):
        correct = 0
        total = 0
        print(class_list[i])
        batch_dataloader = false_negative_dataloader(image_name_lists, class_list[i], transform, batch_size=81)

        for batch_idx, (images, labels) in enumerate(batch_dataloader):
            outputs = model(images)
            labels = labels.float()
            probabilities = torch.softmax(outputs, 1)
            _, predicted = torch.max(probabilities, 1)
            total += labels.size(0)
            print("labels.size(0): ", labels.size(0))
            # print("probabilities: ", probabilities)
            # print("predicted: ", predicted)
            # print("labels: ", labels)
            probabilities_list = probabilities.tolist()
            labels_list = labels.tolist()
            for i in range(len(probabilities_list)):
              if probabilities_list[i].index(max(probabilities_list[i])) == labels_list[i].index(max(labels_list[i])):
                correct += 1
            accuracy.append(correct / total)


  return accuracy

"""# just record this cell running, it shoiuld only take a minute or two"""

print(false_negative_test(final_model, criterion16, optimizer16, transform16))

"""# False negative Test"""

# Data loader for final test
transform = transforms.Compose(
    [transforms.Resize((256, 256)),
    transforms.ToTensor(),
     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])

def false_negative_dataloader(image_name_lists, class_name, transform, batch_size=81):

    # paths
    nv_path = "/content/drive/MyDrive/Final_test_images/nv"
    mel_path = "/content/drive/MyDrive/Final_test_images/mel"
    bkl_path = "/content/drive/MyDrive/Final_test_images/bkl"
    bcc_path = "/content/drive/MyDrive/Final_test_images/bcc"
    akiec_path = "/content/drive/MyDrive/Final_test_images/akiec"


    nv_one_hot = [1, 0, 0, 0, 0]
    mel_one_hot = [0, 1, 0, 0, 0]
    bkl_one_hot = [0, 0, 1, 0, 0]
    bcc_one_hot = [0, 0, 0, 1, 0]
    akiec_one_hot = [0, 0, 0, 0, 1]

    nv_image_list = image_name_lists[0][:81]
    mel_image_list = image_name_lists[1][:81]
    bkl_image_list = image_name_lists[2][:81]
    bcc_image_list = image_name_lists[3][:81]
    akiec_image_list = image_name_lists[4][:81]

    if class_name == "nv":
      one_hot = nv_one_hot
      image_list = nv_image_list
      path = nv_path
    elif class_name == "mel":
      one_hot = mel_one_hot
      image_list = mel_image_list
      path = mel_path
    elif class_name == "bkl":
      one_hot = bkl_one_hot
      image_list = bkl_image_list
      path = bkl_path
    elif class_name == "bcc":
      one_hot = bcc_one_hot
      image_list = bcc_image_list
      path = bcc_path
    elif class_name == "akiec":
      one_hot = akiec_one_hot
      image_list = akiec_image_list
      path = akiec_path
    else:
      print("Invalid class")
      return


    batch_list = []
    for i in range(len(image_list)):
      image = load_image(image_list[i], path, transform)
      image = (image - mean_array) / std_array
      batch_list.append((image.float(), torch.tensor(one_hot)))

    batch_dataloader = DataLoader(batch_list, batch_size=batch_size, shuffle=True)

    return batch_dataloader

def false_negative_test (model, criterion, optimizer, transform):
  model.eval()
  accuracy = []


  nv_path = "/content/drive/MyDrive/Final_test_images/nv"
  mel_path = "/content/drive/MyDrive/Final_test_images/mel"
  bkl_path = "/content/drive/MyDrive/Final_test_images/bkl"
  bcc_path = "/content/drive/MyDrive/Final_test_images/bcc"
  akiec_path = "/content/drive/MyDrive/Final_test_images/akiec"

  paths = [nv_path, mel_path, bkl_path, bcc_path, akiec_path]
  class_list = ["nv", "mel", "bkl", "bcc", "akiec"]

  image_name_lists = []
  for path in paths:
    image_name_lists.append(get_image_names(path))


  with torch.no_grad():
      for i in range(len(class_list)):
        correct = 0
        total = 0
        print(class_list[i])
        batch_dataloader = false_negative_dataloader(image_name_lists, class_list[i], transform, batch_size=81)

        for batch_idx, (images, labels) in enumerate(batch_dataloader):
            outputs = model(images)
            labels = labels.float()
            probabilities = torch.softmax(outputs, 1)
            _, predicted = torch.max(probabilities, 1)
            total += labels.size(0)
            print("labels.size(0): ", labels.size(0))
            # print("probabilities: ", probabilities)
            # print("predicted: ", predicted)
            # print("labels: ", labels)
            probabilities_list = probabilities.tolist()
            labels_list = labels.tolist()
            for i in range(len(probabilities_list)):
              if probabilities_list[i].index(max(probabilities_list[i])) == labels_list[i].index(max(labels_list[i])):
                correct += 1
            accuracy.append(correct / total)


  return accuracy

print(false_negative_test(final_model, criterion16, optimizer16, transform16))